{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Fine-tuning with LoRA on Remote server\n",
    "\n",
    "## Fine-tuning methods\n",
    "- Full fine-tuning\n",
    "- Freeze fine-tuning (Incremental)\n",
    "- Low-Rank Adaptation (LoRA)\n",
    "\n",
    "## What is LoRA？\n",
    "- 通过局部微调，可以在保持原始模型性能的同时，降低模型的大小和计算量\n",
    "- 将原始模型的大矩阵分解为两个小矩阵\n",
    "- 将训练的结果**融合**到原始模型中，以获得更好的性能\n",
    "- 融合的技术有：知识蒸馏、模型融合、模型压缩等\n",
    "\n",
    "## LLaMA-Factory\n",
    "- [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory?tab=readme-ov-file#installation)"
   ],
   "id": "f5828327d75d033b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. Install LLaMA-Factory\n",
    "\n",
    "```bash\n",
    "git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n",
    "cd LLaMA-Factory\n",
    "pip install -e \".[torch,metrics]\"\n",
    "```\n",
    "\n",
    "### 2. Launch LLaMA-Factory webUI\n",
    "\n",
    "```bash\n",
    "nohup llamafactory-cli webui &\n",
    "```\n",
    "- Modify source code to support remote access webUI\n",
    "```bash\n",
    "export GRADIO_SHARE=True\n",
    "export GRADIO_SERVER_NAME=Server_Public_IP\n",
    "```\n",
    "\n",
    "### 3. Download pre-trained model"
   ],
   "id": "ed686f61ed4b1ef1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# !pip install modelscope\n",
    "from modelscope import snapshot_download\n",
    "\n",
    "# Try Meta Llama 3.2 1B Instruct\n",
    "snapshot_download('LLM-Research/Llama-3.2-1B-Instruct', cache_dir='/root/autodl-tmp/models')"
   ],
   "id": "f5730e39b6b6e307"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4. Upload training dataset to LLaMA-Factory project folder\n",
    "\n",
    "```bash\n",
    "# copy dataset to remote server\n",
    "scp ../local_dataset/Llama3Data/fintech.json llamafactory@Server_Public_IP:/path/to/LLaMA-Factory/data\n",
    "\n",
    "# modify dataset_info.json to include the new dataset\n",
    "{\n",
    "  ... ...\n",
    "  \"fintech\": {\n",
    "    \"file_name\": \"fintech.json\"\n",
    "  }\n",
    "}\n",
    "```"
   ],
   "id": "685bdd9938ed1952"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5. WebUI: Configure settings for LLaMA-Factory\n",
    "\n",
    "\n",
    "<img src=\"./assets/llama-factory-lora-configuration-1.jpg\" style=\"margin-left: 0px\" width=1024px>\n",
    "<img src=\"./assets/llama-factory-lora-configuration-2.jpg\" style=\"margin-left: 0px\" width=1024px>\n",
    "<img src=\"./assets/llama-factory-lora-configuration-3.jpg\" style=\"margin-left: 0px\" width=1024px>"
   ],
   "id": "f5e458abcc891170"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### 6. CLI that mapping LlaMA-Factory WebUI settings\n",
    "\n",
    "#### 6.1 Command with parameters:\n",
    "\n",
    "```bash\n",
    "llamafactory-cli train \\\n",
    "    --stage sft \\\n",
    "    --do_train True \\\n",
    "    --model_name_or_path meta-llama/Llama-3.2-1B-Instruct \\\n",
    "    --preprocessing_num_workers 16 \\\n",
    "    --finetuning_type lora \\\n",
    "    --template llama3 \\\n",
    "    --flash_attn auto \\\n",
    "    --dataset_dir data \\\n",
    "    --dataset identity,fintech \\\n",
    "    --cutoff_len 2048 \\\n",
    "    --learning_rate 5e-05 \\\n",
    "    --num_train_epochs 1000.0 \\\n",
    "    --max_samples 10000 \\\n",
    "    --per_device_train_batch_size 10 \\\n",
    "    --gradient_accumulation_steps 8 \\\n",
    "    --lr_scheduler_type cosine \\\n",
    "    --max_grad_norm 1.0 \\\n",
    "    --logging_steps 5 \\\n",
    "    --save_steps 100 \\\n",
    "    --warmup_steps 0 \\\n",
    "    --packing False \\\n",
    "    --report_to none \\\n",
    "    --output_dir saves/Llama-3.2-1B-Instruct/lora/train_2025-01-11-00-05-34 \\\n",
    "    --bf16 True \\\n",
    "    --plot_loss True \\\n",
    "    --trust_remote_code True \\\n",
    "    --ddp_timeout 180000000 \\\n",
    "    --optim adamw_torch \\\n",
    "    --lora_rank 8 \\\n",
    "    --lora_alpha 16 \\\n",
    "    --lora_dropout 0 \\\n",
    "    --lora_target all \\\n",
    "    --val_size 0.02 \\\n",
    "    --eval_strategy steps \\\n",
    "    --eval_steps 100 \\\n",
    "    --per_device_eval_batch_size 10\n",
    "```\n"
   ],
   "id": "ed2d6404370e1ecf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 6.2 Command with configuration file `configuration.yaml`\n",
    "\n",
    "```bash\n",
    "llamafactory-cli train --config configuration.yaml\n",
    "```\n",
    "\n",
    "- yaml content for `configuration.yaml`:\n",
    "\n",
    "```bash\n",
    "top.booster: auto\n",
    "top.checkpoint_path: []\n",
    "top.finetuning_type: lora\n",
    "top.model_name: Llama-3.2-1B-Instruct\n",
    "top.quantization_bit: none\n",
    "top.quantization_method: bitsandbytes\n",
    "top.rope_scaling: none\n",
    "top.template: llama3\n",
    "train.additional_target: ''\n",
    "train.badam_mode: layer\n",
    "train.badam_switch_interval: 50\n",
    "train.badam_switch_mode: ascending\n",
    "train.badam_update_ratio: 0.05\n",
    "train.batch_size: 5\n",
    "train.compute_type: fp16\n",
    "train.create_new_adapter: false\n",
    "train.cutoff_len: 2048\n",
    "train.dataset:\n",
    "- identity\n",
    "- fintech\n",
    "train.dataset_dir: data\n",
    "train.ds_offload: false\n",
    "train.ds_stage: none\n",
    "train.extra_args: '{\"optim\": \"adamw_torch\"}'\n",
    "train.freeze_extra_modules: ''\n",
    "train.freeze_trainable_layers: 2\n",
    "train.freeze_trainable_modules: all\n",
    "train.galore_rank: 16\n",
    "train.galore_scale: 0.25\n",
    "train.galore_target: all\n",
    "train.galore_update_interval: 200\n",
    "train.gradient_accumulation_steps: 8\n",
    "train.learning_rate: 5e-5\n",
    "train.logging_steps: 5\n",
    "train.lora_alpha: 16\n",
    "train.lora_dropout: 0\n",
    "train.lora_rank: 8\n",
    "train.lora_target: ''\n",
    "train.loraplus_lr_ratio: 0\n",
    "train.lr_scheduler_type: cosine\n",
    "train.mask_history: false\n",
    "train.max_grad_norm: '1.0'\n",
    "train.max_samples: '10000'\n",
    "train.neat_packing: false\n",
    "train.neftune_alpha: 0\n",
    "train.num_train_epochs: '1000'\n",
    "train.packing: false\n",
    "train.ppo_score_norm: false\n",
    "train.ppo_whiten_rewards: false\n",
    "train.pref_beta: 0.1\n",
    "train.pref_ftx: 0\n",
    "train.pref_loss: sigmoid\n",
    "train.report_to: false\n",
    "train.resize_vocab: false\n",
    "train.reward_model: null\n",
    "train.save_steps: 100\n",
    "train.shift_attn: false\n",
    "train.swanlab_api_key: ''\n",
    "train.swanlab_mode: cloud\n",
    "train.swanlab_project: llamafactory\n",
    "train.swanlab_run_name: ''\n",
    "train.swanlab_workspace: ''\n",
    "train.train_on_prompt: false\n",
    "train.training_stage: Supervised Fine-Tuning\n",
    "train.use_badam: false\n",
    "train.use_dora: false\n",
    "train.use_galore: false\n",
    "train.use_llama_pro: false\n",
    "train.use_pissa: false\n",
    "train.use_rslora: false\n",
    "train.use_swanlab: false\n",
    "train.val_size: 0.02\n",
    "train.warmup_steps: 0\n",
    "```"
   ],
   "id": "c1531352c65c69bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 7. Using VLLM for inference framework to interact with fine-tuned model\n",
    "\n",
    "- LLaMA-Factory requirements dependencies\n",
    "```bash\n",
    "pip install -e \".[vllm]\"\n",
    "```\n",
    "\n",
    "- LLama-Factory WebUI settings\n",
    "\n",
    "<img src=\"./assets/llama-factory-lora-chat.jpg\" style=\"margin-left: 0px\" width=1024px>\n"
   ],
   "id": "d5741af6f43afa69"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 8. Export Lora model with Pre-trained model\n",
    "\n",
    "- Configuration for exporting model\n",
    "<img src=\"./assets/llama-factory-lora-export-1.jpg\" style=\"margin-left: 0px\" width=1024px>\n",
    "\n",
    "- Server location for exporting model\n",
    "<img src=\"./assets/llama-factory-lora-export-2.jpg\" style=\"margin-left: 0px\" width=1024px>\n",
    "\n",
    "- Chat with the exported model\n",
    "<img src=\"./assets/llama-factory-lora-export-3.jpg\" style=\"margin-left: 0px\" width=1024px>\n",
    "\n",
    "### Future Work - Evaluate & Predict\n",
    "- Validation tool: [OpenCompass](opencompass.github.io)\n",
    "- Quantization"
   ],
   "id": "8606f268b90b7c82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6461f412aac9791a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
