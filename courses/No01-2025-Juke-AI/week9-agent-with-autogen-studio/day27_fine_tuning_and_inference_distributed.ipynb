{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 0. Choose a Multi-GPU Server\n",
    "\n",
    "- 2 x NVIDIA 4096 with CUDA 12.1\n",
    "\n",
    "```shell\n",
    "nvidia-smi\n",
    "\n",
    "nvitop\n",
    "```"
   ],
   "id": "25bddbfe29cd21f7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Multi-GPUs Inference with vLLM\n",
    "\n",
    "- Install vLLM\n",
    "```shell\n",
    "conda create -p /root/autodl-tmp/vllm-env python=3.10 -y\n",
    "conda init\n",
    "conda activate vllm-env\n",
    "```\n",
    "\n",
    "- Install vLLM with CUDA 12.1\n",
    "```shell\n",
    "pip install vllm\n",
    "```\n",
    "\n",
    "- Run vLLM on single Node with 2 GPUs\n",
    "```shell\n",
    "# Enable download model from ModelScope, instead of HuggingFace by default.\n",
    "pip install modelscope\n",
    "export VLLM_USE_MODELSCOPE=true\n",
    "\n",
    "# Pull model online and serve\n",
    "vllm serve deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B --tensor-parallel-size 2\n",
    "\n",
    "# Or use local model\n",
    "vllm serve --tensor-parallel-size 2 --model /root/.cache/modelscope/hub/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\n",
    "```"
   ],
   "id": "69a49e342fbb0b35"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Download ModelScope LLM & Data set",
   "id": "a1e591e93887b742"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# !pip install modelscope, datasets, addict\n",
    "\n",
    "# Download DeepSeek-R1-Distill-Qwen-1.5B model\n",
    "from modelscope import snapshot_download\n",
    "snapshot_download('deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', cache_dir='/root/autodl-tmp/models')\n",
    "\n",
    "# 1. SDK Download Chinese-medical-dialogue dataset in ModelScope format\n",
    "from modelscope.msdatasets import MsDataset\n",
    "ds =  MsDataset.load('xiaofengalg/Chinese-medical-dialogue', subset_name='default', split='train', cache_dir='/root/autodl-tmp/dataset')\n",
    "\n",
    "# 2. CLI Download\n",
    "# modelscope download --dataset xiaofengalg/Chinese-medical-dialogue --local_dir /root/autodl-tmp/dataset\n",
    "\n",
    "# 3. GIT Download\n",
    "# git lfs install\n",
    "# git clone https://www.modelscope.cn/datasets/xiaofengalg/Chinese-medical-dialogue.git\n",
    "\n",
    "# Convert dataset to LLaMA-Factory format\n",
    "# python convert.py"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Download LlamaFactory\n",
    "\n",
    "```shell\n",
    "git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n",
    "cd LLaMA-Factory\n",
    "pip install -e \".[torch,metrics]\"\n",
    "\n",
    "nohup llamafactory-cli webui &\n",
    "```"
   ],
   "id": "ff13a81e2eb8f095"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Multi-GPUs Fine-tuning with LlamaFactory",
   "id": "2d07081a8bccb81d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Evaluate the model\n",
    "- https://modelscope.cn/datasets/modelscope/R1-Distill-Math-Test"
   ],
   "id": "ba21fd178cd7d60e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
