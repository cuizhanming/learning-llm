{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d0faef-0ef0-4a1b-a7d8-99f59cd72a09",
   "metadata": {},
   "source": [
    "# 第4章 LlamaIndex知识管理与信息检索\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec8c5bb",
   "metadata": {},
   "source": [
    "## 💡 学习目标\n",
    "\n",
    "1. 掌握 LlamaIndex 的特点和基本用法\n",
    "2. 掌握 LlamaIndex 内置的工具\n",
    "3. 如何用好 SDK 简化基于 LLM 的应用开发\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194427bf-5807-49d4-ab25-fa0556f835f3",
   "metadata": {},
   "source": [
    "## 1. 大语言模型开发框架的价值是什么？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb60e6e5-8f2a-4cd5-a4b5-824259afc229",
   "metadata": {},
   "source": [
    "_SDK：Software Development Kit，它是一组软件工具和资源的集合，旨在帮助开发者创建、测试、部署和维护应用程序或软件。_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d08668-4981-4b84-ae07-f74cfa191309",
   "metadata": {},
   "source": [
    "所有开发框架（SDK）的核心价值，都是降低开发、维护成本。\n",
    "\n",
    "大语言模型开发框架的价值，是让开发者可以更方便地开发基于大语言模型的应用。主要提供两类帮助：\n",
    "\n",
    "1. 第三方能力抽象。比如 LLM、向量数据库、搜索接口等\n",
    "2. 常用工具、方案封装\n",
    "3. 底层实现封装。比如流式接口、超时重连、异步与并行等\n",
    "\n",
    "好的开发框架，需要具备以下特点：\n",
    "\n",
    "1. 可靠性、鲁棒性高\n",
    "2. 可维护性高\n",
    "3. 可扩展性高\n",
    "4. 学习成本低\n",
    "\n",
    "举些通俗的例子：\n",
    "\n",
    "- 与外部功能解依赖\n",
    "  - 比如可以随意更换 LLM 而不用大量重构代码\n",
    "  - 更换三方工具也同理\n",
    "- 经常变的部分要在外部维护而不是放在代码里\n",
    "  - 比如 Prompt 模板\n",
    "- 各种环境下都适用\n",
    "  - 比如线程安全\n",
    "- 方便调试和测试\n",
    "  - 至少要能感觉到用了比不用方便吧\n",
    "  - 合法的输入不会引发框架内部的报错\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>选对了框架，事半功倍；反之，事倍功半。\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579b589b-5a4e-451e-baf0-d2a409a9cb4b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>什么是 SDK?</b> https://aws.amazon.com/cn/what-is/sdk/\n",
    "<br/>\n",
    "<b>SDK 和 API 的区别是什么?</b> https://aws.amazon.com/cn/compare/the-difference-between-sdk-and-api/\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30361cf7-ec31-4c45-871e-28ac4f0db1a9",
   "metadata": {},
   "source": [
    "#### 🌰 举个例子：使用 SDK，4 行代码实现一个简易的 RAG 系统\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2517bfe1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<p>LlamaIndex 默认的 Embedding 模型是 <code>OpenAIEmbedding(model=\"text-embedding-ada-002\")</code></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "id": "bb03dc82-649d-4fe8-8ba5-023220c8cb22",
   "metadata": {},
   "source": [
    "# !pip install --upgrade llama-index\n",
    "\n",
    "# !pip install llama-index-llms-dashscope\n",
    "# !pip install llama-index-llms-openai-like\n",
    "# !pip install llama-index-embeddings-dashscope"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f36875ae",
   "metadata": {},
   "source": [
    "import os\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "from llama_index.llms.dashscope import DashScope, DashScopeGenerationModels\n",
    "from llama_index.embeddings.dashscope import DashScopeEmbedding, DashScopeTextEmbeddingModels\n",
    "\n",
    "# LlamaIndex默认使用的大模型被替换为百炼\n",
    "# Settings.llm = OpenAILike(\n",
    "#     model=\"qwen-max\",\n",
    "#     api_base=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "#     api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "#     is_chat_model=True\n",
    "# )\n",
    "\n",
    "Settings.llm = DashScope(model_name=DashScopeGenerationModels.QWEN_MAX, api_key=os.getenv(\"DASHSCOPE_API_KEY\"))\n",
    "\n",
    "# LlamaIndex默认使用的Embedding模型被替换为百炼的Embedding模型\n",
    "Settings.embed_model = DashScopeEmbedding(\n",
    "    # model_name=\"text-embedding-v1\"\n",
    "    model_name=DashScopeTextEmbeddingModels.TEXT_EMBEDDING_V1,\n",
    "    # api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dea32ce7-c7a7-4692-a217-45cf632281ae",
   "metadata": {},
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"./data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"deepseek v3有多少参数？\")\n",
    "\n",
    "# print(response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "24e4c617-2fb8-489d-a0d0-34d5ca196f1c",
   "metadata": {},
   "source": [
    "## 2. LlamaIndex 介绍\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313487e1-a2c7-4d4b-ad41-e3a9f0a0b07e",
   "metadata": {},
   "source": [
    "官网标题：_「 Build AI Knowledge Assistants over your enterprise data 」_\n",
    "\n",
    "LlamaIndex 是一个为开发「知识增强」的大语言模型应用的框架（也就是 SDK）。**知识增强**，泛指任何在私有或特定领域数据基础上应用大语言模型的情况。例如：\n",
    "\n",
    "<img src=\"./assets/basic_rag.png\" width=800px>\n",
    "\n",
    "- Question-Answering Chatbots (也就是 RAG)\n",
    "- Document Understanding and Extraction （文档理解与信息抽取）\n",
    "\n",
    "- Autonomous Agents that can perform research and take actions （智能体应用）\n",
    "- Workflow orchestrating single and multi-agent (编排单个或多个智能体形成工作流）\n",
    "\n",
    "LlamaIndex 有 Python 和 Typescript 两个版本，Python 版的文档相对更完善。\n",
    "\n",
    "- Python 文档地址：https://docs.llamaindex.ai/en/stable/\n",
    "- Python API 接口文档：https://docs.llamaindex.ai/en/stable/api_reference/\n",
    "\n",
    "- TS 文档地址：https://ts.llamaindex.ai/\n",
    "\n",
    "LlamaIndex 是一个开源框架，Github 链接：https://github.com/run-llama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4822b2-52d5-411c-8244-3432f8733da2",
   "metadata": {},
   "source": [
    "### LlamaIndex 的核心模块\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c474b43-018a-4687-a51e-54b391a6bbca",
   "metadata": {},
   "source": [
    "<img src=\"./assets/llamaindex.png\" alt=\"LlamaIndex 核心模块\" width=\"1400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca66bf37-48e4-45eb-9e7e-a24e86108ac1",
   "metadata": {},
   "source": [
    "### 安装 LlamaIndex\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "f80bba90",
   "metadata": {},
   "source": [
    "# ！pip install llama-index"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "74341a28-fb7f-4e5b-9342-cf5cd850654a",
   "metadata": {},
   "source": [
    "## 3.数据加载（Loading）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d134a56-ae9a-41a5-a703-ce9dfb3fc600",
   "metadata": {},
   "source": [
    "### 3.1、加载本地数据\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35bfa25-9a09-4c40-afa1-9f9156e56dc2",
   "metadata": {},
   "source": [
    "`SimpleDirectoryReader` 是一个简单的本地文件加载器。它会遍历指定目录，并根据文件扩展名自动加载文件（**文本内容**）。\n",
    "\n",
    "支持的文件类型：\n",
    "\n",
    "- `.csv` - comma-separated values\n",
    "- `.docx` - Microsoft Word\n",
    "- `.epub` - EPUB ebook format\n",
    "- `.hwp` - Hangul Word Processor\n",
    "- `.ipynb` - Jupyter Notebook\n",
    "- `.jpeg`, `.jpg` - JPEG image\n",
    "- `.mbox` - MBOX email archive\n",
    "- `.md` - Markdown\n",
    "- `.mp3`, `.mp4` - audio and video\n",
    "- `.pdf` - Portable Document Format\n",
    "- `.png` - Portable Network Graphics\n",
    "- `.ppt`, `.pptm`, `.pptx` - Microsoft PowerPoint\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "05b6a279-3eca-4685-af91-80fb443fca1d",
   "metadata": {},
   "source": [
    "import json\n",
    "from pydantic.v1 import BaseModel\n",
    "\n",
    "def show_json(data):\n",
    "    \"\"\"用于展示json数据\"\"\"\n",
    "    if isinstance(data, str):\n",
    "        obj = json.loads(data)\n",
    "        print(json.dumps(obj, indent=4, ensure_ascii=False))\n",
    "    elif isinstance(data, dict) or isinstance(data, list):\n",
    "        print(json.dumps(data, indent=4, ensure_ascii=False))\n",
    "    elif issubclass(type(data), BaseModel):\n",
    "        print(json.dumps(data.dict(), indent=4, ensure_ascii=False))\n",
    "\n",
    "def show_list_obj(data):\n",
    "    \"\"\"用于展示一组对象\"\"\"\n",
    "    if isinstance(data, list):\n",
    "        for item in data:\n",
    "            show_json(item)\n",
    "    else:\n",
    "        raise ValueError(\"Input is not a list\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "198ebc20-fab6-46a9-8cca-4b114fe2640f",
   "metadata": {},
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "reader = SimpleDirectoryReader(\n",
    "        input_dir=\"./data\", # 目标目录\n",
    "        recursive=False, # 是否递归遍历子目录\n",
    "        required_exts=[\".pdf\"] # (可选)只读取指定后缀的文件\n",
    "    )\n",
    "documents = reader.load_data()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dfb3f1ac-75cb-4c5e-b0a1-53621d8d325e",
   "metadata": {},
   "source": [
    "print(documents[0].text)\n",
    "show_json(documents[0].json())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "277be7f4-1993-4b74-bd3e-f9d8cb5a827d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>注意：</b>对图像、视频、语音类文件，默认不会自动提取其中文字。如需提取，参考下面介绍的 <code>Data Connectors</code>。\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c98851-0858-4215-858d-bea70e310d5f",
   "metadata": {},
   "source": [
    "默认的 `PDFReader` 效果并不理想，我们可以更换文件加载器\n",
    "\n",
    "<b>LlamaParse</b>\n",
    "\n",
    "首先，登录并从 https://cloud.llamaindex.ai ↗ 注册并获取 api-key 。\n",
    "\n",
    "然后，安装该包："
   ]
  },
  {
   "cell_type": "code",
   "id": "d25c97cb",
   "metadata": {},
   "source": [
    "# !pip install llama-cloud-services"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b093a88b-5d4a-423b-bfe7-fa28b34744e1",
   "metadata": {},
   "source": [
    "# 在系统环境变量里配置 LLAMA_CLOUD_API_KEY=XXX\n",
    "\n",
    "from llama_cloud_services import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply() # 只在Jupyter笔记环境中需要此操作，否则会报错\n",
    "\n",
    "# set up parser\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\"  # \"markdown\" and \"text\" are available\n",
    ")\n",
    "file_extractor = {\".pdf\": parser}\n",
    "\n",
    "documents = SimpleDirectoryReader(input_dir=\"./data\", required_exts=[\".pdf\"], file_extractor=file_extractor).load_data()\n",
    "print(documents[0].text)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a116d296-e4a4-4710-a41a-318bbab8ec24",
   "metadata": {},
   "source": [
    "### 3.2、Data Connectors\n",
    "\n",
    "用于处理更丰富的数据类型，并将其读取为 `Document` 的形式。\n",
    "\n",
    "例如：直接读取网页\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "19471210-6cb3-4822-8bad-dc701b6ab335",
   "metadata": {},
   "source": [
    "# !pip install llama-index-readers-web"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2d73abf3-91df-488c-a5f3-c7de0c6d4c44",
   "metadata": {},
   "source": [
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "\n",
    "documents = SimpleWebPageReader(html_to_text=True).load_data(\n",
    "    [\"https://edu.guangjuke.com/tx/\"]\n",
    ")\n",
    "\n",
    "print(documents[0].text)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "02a88893-01b8-44a1-9bed-e93e60cec328",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>更多 Data Connectors</b>\n",
    "    <ul>\n",
    "        <li>内置的<a href=\"https://llamahub.ai/l/readers/llama-index-readers-file\">文件加载器</a></li>\n",
    "        <li>连接三方服务的<a href=\"https://docs.llamaindex.ai/en/stable/module_guides/loading/connector/modules/\">数据加载器</a>，例如数据库</li>\n",
    "        <li>更多加载器可以在 <a href=\"https://llamahub.ai/\">LlamaHub</a> 上找到</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed8a42-f6fc-430f-9e92-07736e7f359c",
   "metadata": {},
   "source": [
    "## 4. 文本切分与解析（Chunking）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ad7ebd-9e56-47f9-8136-2e1098139c01",
   "metadata": {},
   "source": [
    "为方便检索，我们通常把 `Document` 切分为 `Node`。\n",
    "\n",
    "在 LlamaIndex 中，`Node` 被定义为一个文本的「chunk」。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4881c7d9-9107-4704-b322-d3bc34af96f2",
   "metadata": {},
   "source": [
    "### 4.1、使用 TextSplitters 对文本做切分\n",
    "\n",
    "例如：`TokenTextSplitter` 按指定 token 数切分文本\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "69a083f7-cda9-45d9-be3e-397ce866e440",
   "metadata": {},
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "\n",
    "node_parser = TokenTextSplitter(\n",
    "    chunk_size=512,  # 每个 chunk 的最大长度\n",
    "    chunk_overlap=200  # chunk 之间重叠长度\n",
    ")\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents(\n",
    "    documents, show_progress=False\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "81b363de-c5ef-4e20-ad4d-39bccabb3369",
   "metadata": {},
   "source": [
    "show_json(nodes[1].json())\n",
    "show_json(nodes[2].json())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d1f56dbf-4247-4a06-a127-2fa1929455f0",
   "metadata": {},
   "source": [
    "LlamaIndex 提供了丰富的 `TextSplitter`，例如：\n",
    "\n",
    "- [`SentenceSplitter`](https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/sentence_splitter/)：在切分指定长度的 chunk 同时尽量保证句子边界不被切断；\n",
    "- [`CodeSplitter`](https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/code/)：根据 AST（编译器的抽象句法树）切分代码，保证代码功能片段完整；\n",
    "- [`SemanticSplitterNodeParser`](https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/semantic_splitter/)：根据语义相关性对将文本切分为片段。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b692f9fb-af99-4bf5-9d4e-c745438173d6",
   "metadata": {},
   "source": [
    "### 4.2、使用 NodeParsers 对有结构的文档做解析\n",
    "\n",
    "例如：`HTMLNodeParser`解析 HTML 文档\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "b7c6f533-a203-42a2-b312-3d89e0cbf22a",
   "metadata": {},
   "source": [
    "from llama_index.core.node_parser import HTMLNodeParser\n",
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "\n",
    "documents = SimpleWebPageReader(html_to_text=False).load_data(\n",
    "    [\"https://edu.guangjuke.com/tx/\"]\n",
    ")\n",
    "\n",
    "# 默认解析 [\"p\", \"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\", \"li\", \"b\", \"i\", \"u\", \"section\"]\n",
    "parser = HTMLNodeParser(tags=[\"span\"])  # 可以自定义解析哪些标签\n",
    "nodes = parser.get_nodes_from_documents(documents)\n",
    "\n",
    "for node in nodes:\n",
    "    print(node.text+\"\\n\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9bdc613c-36a8-4afb-871b-097496703eaf",
   "metadata": {},
   "source": [
    "更多的 `NodeParser` 包括 [`MarkdownNodeParser`](https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/markdown/)，[`JSONNodeParser`](https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/json/)等等。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b8557f-20af-477d-918d-14761a9c986d",
   "metadata": {},
   "source": [
    "## 5. 索引（Indexing）与检索（Retrieval）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df338b16-df37-412d-a385-2d1f4b681112",
   "metadata": {},
   "source": [
    "**基础概念**：在「检索」相关的上下文中，「索引」即`index`， 通常是指为了实现快速检索而设计的特定「数据结构」。\n",
    "\n",
    "索引的具体原理与实现不是本课程的教学重点，感兴趣的同学可以参考：[传统索引](https://en.wikipedia.org/wiki/Search_engine_indexing)、[向量索引](https://medium.com/kx-systems/vector-indexing-a-roadmap-for-vector-databases-65866f07daf5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd397fe-8932-49de-ac37-bed0b585205c",
   "metadata": {},
   "source": [
    "### 5.1、向量检索\n",
    "\n",
    "1. `VectorStoreIndex` 直接在内存中构建一个 Vector Store 并建索引\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4ea17e80-d25c-43ac-b9b5-983c6acb3adb",
   "metadata": {},
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import TokenTextSplitter, SentenceSplitter\n",
    "\n",
    "# 加载 pdf 文档\n",
    "documents = SimpleDirectoryReader(\n",
    "    \"./data\", \n",
    "    required_exts=[\".pdf\"],\n",
    ").load_data()\n",
    "\n",
    "# 定义 Node Parser\n",
    "node_parser = TokenTextSplitter(chunk_size=512, chunk_overlap=200)\n",
    "\n",
    "# 切分文档\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "\n",
    "# 构建 index，默认是在内存中\n",
    "index = VectorStoreIndex(nodes)\n",
    "\n",
    "# 另外一种实现方式\n",
    "# index = VectorStoreIndex.from_documents(documents=documents, transformations=[SentenceSplitter(chunk_size=512)])\n",
    "\n",
    "# 写入本地文件\n",
    "# index.storage_context.persist(persist_dir=\"./doc_emb\")\n",
    "\n",
    "# 获取 retriever\n",
    "vector_retriever = index.as_retriever(\n",
    "    similarity_top_k=2 # 返回2个结果\n",
    ")\n",
    "\n",
    "# 检索\n",
    "results = vector_retriever.retrieve(\"deepseek v3数学能力怎么样？\")\n",
    "\n",
    "print(results[0].text)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "90ebec20-7c12-4d2d-a4f4-5cb2abcc5f32",
   "metadata": {},
   "source": [
    "2. 使用自定义的 Vector Store，以 `Qdrant` 为例：\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4b5e7648-0598-4df7-923f-42fe2f172da3",
   "metadata": {},
   "source": [
    "# !pip install llama-index-vector-stores-qdrant"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a65a38da-3e71-4fa8-872d-eff6b4f3856b",
   "metadata": {},
   "source": [
    "from llama_index.core.indices.vector_store.base import VectorStoreIndex\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "client = QdrantClient(location=\":memory:\")\n",
    "collection_name = \"demo\"\n",
    "collection = client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE)\n",
    ")\n",
    "\n",
    "vector_store = QdrantVectorStore(client=client, collection_name=collection_name)\n",
    "# storage: 指定存储空间\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# 创建 index：通过 Storage Context 关联到自定义的 Vector Store\n",
    "index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
    "\n",
    "# 获取 retriever\n",
    "vector_retriever = index.as_retriever(similarity_top_k=1)\n",
    "\n",
    "# 检索\n",
    "results = vector_retriever.retrieve(\"deepseek v3数学能力怎么样\")\n",
    "\n",
    "print(results[0])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9913e5d5-7c84-4833-b21d-2fe440749a63",
   "metadata": {},
   "source": [
    "### 5.2、更多索引与检索方式\n",
    "\n",
    "LlamaIndex 内置了丰富的检索机制，例如：\n",
    "\n",
    "- 关键字检索\n",
    "\n",
    "  - [`BM25Retriever`](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/bm25/)：基于 tokenizer 实现的 BM25 经典检索算法\n",
    "  - [`KeywordTableGPTRetriever`](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/keyword/#llama_index.core.indices.keyword_table.retrievers.KeywordTableGPTRetriever)：使用 GPT 提取检索关键字\n",
    "  - [`KeywordTableSimpleRetriever`](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/keyword/#llama_index.core.indices.keyword_table.retrievers.KeywordTableSimpleRetriever)：使用正则表达式提取检索关键字\n",
    "  - [`KeywordTableRAKERetriever`](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/keyword/#llama_index.core.indices.keyword_table.retrievers.KeywordTableRAKERetriever)：使用[`RAKE`](https://pypi.org/project/rake-nltk/)算法提取检索关键字（有语言限制）\n",
    "\n",
    "- RAG-Fusion [`QueryFusionRetriever`](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/query_fusion/)\n",
    "\n",
    "- 还支持 [KnowledgeGraph](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/knowledge_graph/)、[SQL](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/sql/#llama_index.core.retrievers.SQLRetriever)、[Text-to-SQL](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/sql/#llama_index.core.retrievers.NLSQLRetriever) 等等\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af53e99b-2ab5-4520-ba96-4a9979a94480",
   "metadata": {},
   "source": [
    "### 5.3、检索后处理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c53c7c-9077-42bc-a5c0-832688b352b8",
   "metadata": {},
   "source": [
    "LlamaIndex 的 `Node Postprocessors` 提供了一系列检索后处理模块。\n",
    "\n",
    "例如：我们可以用不同模型对检索后的 `Nodes` 做重排序\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7176f29c-be6b-491c-b2e8-6e604ad201b4",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 获取 retriever\n",
    "vector_retriever = index.as_retriever(similarity_top_k=5)\n",
    "\n",
    "# 检索\n",
    "nodes = vector_retriever.retrieve(\"deepseek v3有多少参数?\")\n",
    "\n",
    "for i, node in enumerate(nodes):\n",
    "    print(f\"[{i}] {node.text}\\n\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "65bae2b4-7c36-44fa-9566-0d1b3f34972a",
   "metadata": {},
   "source": [
    "from llama_index.core.postprocessor import LLMRerank\n",
    "\n",
    "postprocessor = LLMRerank(top_n=2)\n",
    "\n",
    "nodes = postprocessor.postprocess_nodes(nodes, query_str=\"deepseek v3有多少参数?\")\n",
    "\n",
    "for i, node in enumerate(nodes):\n",
    "    print(f\"[{i}] {node.text}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "69ca41ea-3112-491a-a1a1-5ec8db295b61",
   "metadata": {},
   "source": [
    "更多的 Rerank 及其它后处理方法，参考官方文档：[Node Postprocessor Modules](https://docs.llamaindex.ai/en/stable/module_guides/querying/node_postprocessors/node_postprocessors/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392d8d69-cd42-445c-a0cd-0dd7c66d07bc",
   "metadata": {},
   "source": [
    "## 6. 生成回复（QA & Chat）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4248c1-602c-4df6-bd6a-72e994faf1ed",
   "metadata": {},
   "source": [
    "### 6.1 单轮问答（Query Engine）\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "261d35c3-8b54-4840-ab88-c04b348b0fb7",
   "metadata": {},
   "source": [
    "qa_engine = index.as_query_engine()\n",
    "response = qa_engine.query(\"deepseek v3数学能力怎么样?\")\n",
    "\n",
    "print(response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "44d55521-5b67-4c26-a8de-440d2e1046a7",
   "metadata": {},
   "source": [
    "#### 流式输出\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "1817400e-9311-4161-89e4-507267862524",
   "metadata": {},
   "source": [
    "qa_engine = index.as_query_engine(streaming=True)\n",
    "response = qa_engine.query(\"deepseek v3数学能力怎么样?\")\n",
    "response.print_response_stream()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1cf53205-beb2-4571-81aa-c5f8e12142f5",
   "metadata": {},
   "source": [
    "### 6.2 多轮对话（Chat Engine）\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "81a73a48-469e-4d40-adf3-e0e5ec44305a",
   "metadata": {},
   "source": [
    "chat_engine = index.as_chat_engine()\n",
    "response = chat_engine.chat(\"deepseek v3数学能力怎么样?\")\n",
    "print(response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "712c8c71-6420-4c6f-821c-1bd1c31dc8bc",
   "metadata": {},
   "source": [
    "response = chat_engine.chat(\"代码能力呢?\")\n",
    "print(response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3094d188-2241-4995-9704-1d2aeb878e1e",
   "metadata": {},
   "source": [
    "#### 流式输出\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "bf33effa-ad36-4eea-b1d1-926ca5cc8dff",
   "metadata": {},
   "source": [
    "chat_engine = index.as_chat_engine()\n",
    "streaming_response = chat_engine.stream_chat(\"deepseek v3数学能力怎么样?\")\n",
    "# streaming_response.print_response_stream()\n",
    "for token in streaming_response.response_gen:\n",
    "    print(token, end=\"\", flush=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d7eb76fa-e4ba-4c47-9785-53eadddf478e",
   "metadata": {},
   "source": [
    "## 7. 底层接口：Prompt、LLM 与 Embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0cce84-9f79-41ef-a6c4-caaeb70d029e",
   "metadata": {},
   "source": [
    "### 7.1 Prompt 模板\n",
    "\n",
    "#### `PromptTemplate` 定义提示词模板\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "41358d83-4fcb-430c-9c2e-c1ac0839cbfe",
   "metadata": {},
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\"写一个关于{topic}的笑话\")\n",
    "\n",
    "prompt.format(topic=\"小明\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a4a94232-e8d5-4bf2-8751-8851d924fcee",
   "metadata": {},
   "source": [
    "#### `ChatPromptTemplate` 定义多轮消息模板\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "edb05592-835f-4cb2-bfa0-862796c36fdf",
   "metadata": {},
   "source": [
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core import ChatPromptTemplate\n",
    "\n",
    "chat_text_qa_msgs = [\n",
    "    ChatMessage(\n",
    "        role=MessageRole.SYSTEM,\n",
    "        content=\"你叫{name}，你必须根据用户提供的上下文回答问题。\",\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        role=MessageRole.USER, \n",
    "        content=(\n",
    "            \"已知上下文：\\n\" \\\n",
    "            \"{context}\\n\\n\" \\\n",
    "            \"问题：{question}\"\n",
    "        )\n",
    "    ),\n",
    "]\n",
    "text_qa_template = ChatPromptTemplate(chat_text_qa_msgs)\n",
    "\n",
    "print(\n",
    "    text_qa_template.format(\n",
    "        name=\"小明\",\n",
    "        context=\"这是一个测试\",\n",
    "        question=\"这是什么\"\n",
    "    )\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c98931d9-f411-4433-9900-649f74a40b6e",
   "metadata": {},
   "source": [
    "### 7.2 语言模型\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "1febbfc2-06c1-4692-9ac1-8843e5554098",
   "metadata": {},
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0, model=\"gpt-4o\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0c0d3842-32ff-4510-9853-47e7282b56e6",
   "metadata": {},
   "source": [
    "response = llm.complete(prompt.format(topic=\"小明\"))\n",
    "\n",
    "print(response.text)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d0cbe1cc-9dfc-4274-8cdd-b4dd6d3eb5bb",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "response = llm.complete(\n",
    "    text_qa_template.format(\n",
    "        name=\"小明\",\n",
    "        context=\"这是一个测试\",\n",
    "        question=\"你是谁，我们在干嘛\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(response.text)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4234c43f-d46c-4755-afb3-ade10c308bf8",
   "metadata": {},
   "source": [
    "#### 连接DeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "id": "ad92e176-6153-4059-a01b-e2957a052a6c",
   "metadata": {},
   "source": [
    "# !pip install llama-index-llms-deepseek"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "511a86bd-c5eb-45e7-8e0a-7e56b2fe7f7d",
   "metadata": {},
   "source": [
    "import os\n",
    "from llama_index.llms.deepseek import DeepSeek\n",
    "\n",
    "llm = DeepSeek(model=\"deepseek-chat\", api_key=os.getenv(\"DEEPSEEK_API_KEY\"), temperature=1.5)\n",
    "\n",
    "response = llm.complete(\"写个笑话\")\n",
    "print(response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2f49f6da-d220-4c36-b697-e3b525902af7",
   "metadata": {},
   "source": [
    "#### 设置全局使用的语言模型\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "94943bec-563c-44b5-80bb-9c0a7c05382c",
   "metadata": {},
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = DeepSeek(model=\"deepseek-chat\", api_key=os.getenv(\"DEEPSEEK_API_KEY\"), temperature=1.5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "63dd7b76-2594-4c39-8e81-33e3c985df38",
   "metadata": {},
   "source": [
    "除 OpenAI 外，LlamaIndex 已集成多个大语言模型，包括云服务 API 和本地部署 API，详见官方文档：[Available LLM integrations](https://docs.llamaindex.ai/en/stable/module_guides/models/llms/modules/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b110fc0b-ec6c-445b-a3c2-3ddef41d9589",
   "metadata": {},
   "source": [
    "### 7.3 Embedding 模型\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c5be1257-eb1a-4e2d-bad9-2cd002841093",
   "metadata": {},
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# 全局设定\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\", dimensions=512)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eb025ce6-c065-4cf2-9e9d-5a01f04c26ee",
   "metadata": {},
   "source": [
    "LlamaIndex 同样集成了多种 Embedding 模型，包括云服务 API 和开源模型（HuggingFace）等，详见[官方文档](https://docs.llamaindex.ai/en/stable/module_guides/models/embeddings/)。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be91aa7d-6f3a-4387-859c-c7357d7c5d15",
   "metadata": {},
   "source": [
    "## 8. 基于 LlamaIndex 实现一个功能较完整的 RAG 系统\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a1b844-605e-4be2-9cae-2e9e56e46b40",
   "metadata": {},
   "source": [
    "功能要求：\n",
    "\n",
    "- 加载指定目录的文件\n",
    "- 支持 RAG-Fusion\n",
    "- 使用 Qdrant 向量数据库，并持久化到本地\n",
    "- 支持检索后排序\n",
    "- 支持多轮对话\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "90348baf-3a5e-4cc4-968d-e90f9d315495",
   "metadata": {},
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "EMBEDDING_DIM = 1536\n",
    "COLLECTION_NAME = \"full_demo\"\n",
    "PATH = \"./qdrant_db\"\n",
    "\n",
    "client = QdrantClient(path=PATH)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cf485f1b-7da4-412e-a121-a7e6b5f3ece9",
   "metadata": {},
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, get_response_synthesizer\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.response_synthesizers import ResponseMode\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core.postprocessor import LLMRerank, SimilarityPostprocessor\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.chat_engine import CondenseQuestionChatEngine\n",
    "from llama_index.llms.dashscope import DashScope, DashScopeGenerationModels\n",
    "from llama_index.embeddings.dashscope import DashScopeEmbedding, DashScopeTextEmbeddingModels\n",
    "\n",
    "# 1. 指定全局llm与embedding模型\n",
    "Settings.llm = DashScope(model_name=DashScopeGenerationModels.QWEN_MAX,api_key=os.getenv(\"DASHSCOPE_API_KEY\"))\n",
    "Settings.embed_model = DashScopeEmbedding(model_name=DashScopeTextEmbeddingModels.TEXT_EMBEDDING_V1)\n",
    "\n",
    "# 2. 指定全局文档处理的 Ingestion Pipeline\n",
    "Settings.transformations = [SentenceSplitter(chunk_size=512, chunk_overlap=200)]\n",
    "\n",
    "# 3. 加载本地文档\n",
    "documents = SimpleDirectoryReader(\"./data\").load_data()\n",
    "\n",
    "if client.collection_exists(collection_name=COLLECTION_NAME):\n",
    "    client.delete_collection(collection_name=COLLECTION_NAME)\n",
    "\n",
    "# 4. 创建 collection\n",
    "client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config=VectorParams(size=EMBEDDING_DIM, distance=Distance.COSINE)\n",
    ")\n",
    "\n",
    "# 5. 创建 Vector Store\n",
    "vector_store = QdrantVectorStore(client=client, collection_name=COLLECTION_NAME)\n",
    "\n",
    "# 6. 指定 Vector Store 的 Storage 用于 index\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")\n",
    "\n",
    "# 7. 定义检索后排序模型\n",
    "reranker = LLMRerank(top_n=2)\n",
    "# 最终打分低于0.6的文档被过滤掉\n",
    "sp = SimilarityPostprocessor(similarity_cutoff=0.6)\n",
    "\n",
    "# 8. 定义 RAG Fusion 检索器\n",
    "fusion_retriever = QueryFusionRetriever(\n",
    "    [index.as_retriever()],\n",
    "    similarity_top_k=5, # 检索召回 top k 结果\n",
    "    num_queries=3,  # 生成 query 数\n",
    "    use_async=False,\n",
    "    # query_gen_prompt=\"\",  # 可以自定义 query 生成的 prompt 模板\n",
    ")\n",
    "\n",
    "# 9. 构建单轮 query engine\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    fusion_retriever,\n",
    "    node_postprocessors=[reranker],\n",
    "    response_synthesizer=get_response_synthesizer(\n",
    "        response_mode = ResponseMode.REFINE\n",
    "    )\n",
    ")\n",
    "\n",
    "# 10. 对话引擎\n",
    "chat_engine = CondenseQuestionChatEngine.from_defaults(\n",
    "    query_engine=query_engine, \n",
    "    # condense_question_prompt=\"\" # 可以自定义 chat message prompt 模板\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0124ef05-eb4b-417b-aa56-7128460162dd",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 测试多轮对话\n",
    "# User: deepseek v3有多少参数\n",
    "# User: 每次激活多少\n",
    "\n",
    "while True:\n",
    "    question=input(\"User:\")\n",
    "    if question.strip() == \"\":\n",
    "        break\n",
    "    response = chat_engine.chat(question)\n",
    "    print(f\"AI: {response}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0de36489",
   "metadata": {},
   "source": [
    "## 9. Text2SQL / NL2SQL / NL2Chart / ChatBI\n",
    "\n",
    "#### 9.1 基本介绍\n",
    "\n",
    "Text2SQL 是一种将自然语言转换为SQL查询语句的技术。\n",
    "\n",
    "这项技术的意义：让每个人都能像对话一样查询数据库，获取所需信息，而不必学习SQL语法。\n",
    "\n",
    "#### 9.2 典型应用场景\n",
    "\n",
    "- 业务分析师的数据自助服务\n",
    "\n",
    "- 智能BI与数据可视化\n",
    "\n",
    "- 客服与内部数据库查询\n",
    "\n",
    "- 跨部门数据协作与分享\n",
    "\n",
    "- 运营数据分析与决策支持\n",
    "\n",
    "\n",
    "#### 9.3 Text2SQL核心能力与挑战\n",
    "\n",
    "一个成熟的Text2SQL系统需要具备以下关键能力：\n",
    "\n",
    "| 核心能力       | 说明                   | 技术挑战             |\n",
    "| -------------- | ---------------------- | -------------------- |\n",
    "| 语义理解       | 理解用户真正的查询意图 | 处理歧义、上下文推断 |\n",
    "| 数据库结构感知 | 了解表结构、字段关系   | 自动映射字段与实体   |\n",
    "| 复杂查询构建   | 支持多表连接、聚合等   | 子查询、嵌套逻辑转换 |\n",
    "| 上下文记忆     | 理解多轮对话中的指代   | 维护查询状态         |\n",
    "| 错误处理       | 识别并修正错误输入     | 模糊匹配、容错机制   |\n",
    "\n",
    "#### 9.4 实现Text2SQL的技术架构\n",
    "\n",
    "- 架构一：基于Workflow工作流方案\n",
    "\n",
    "- 架构二：基于LangChain的数据库链方案\n",
    "\n",
    "- 架构三：企业级解决方案\n",
    "\n",
    "    1. Vanna（开源）\n",
    "\n",
    "        - 官网：https://vanna.ai/\n",
    "\n",
    "    2. 阿里云（商业）\n",
    "\n",
    "        - [自然语言到SQL语言转义（基于大语言模型的NL2SQL）](http://help.aliyun.com/zh/polardb/polardb-for-mysql/user-guide/llm-based-nl2sql?spm=a2c4g.11186623.help-menu-2249963.d_5_25_1_0.5d942b63IaNo7t&scm=20140722.H_2669074._.OR_help-T_cn~zh-V_1)\n",
    "\n",
    "        - [自然语言生成智能图表NL2Chart](https://help.aliyun.com/zh/polardb/polardb-for-mysql/user-guide/nl2chart?spm=a2c4g.11186623.help-menu-2249963.d_5_25_1_1.16325ef0KtuFXl&scm=20140722.H_2922405._.OR_help-T_cn~zh-V_1)\n",
    "\n",
    "    3. 腾讯云（商业）\n",
    "\n",
    "        - ChatBI产品 https://cloud.tencent.com/document/product/590/107689"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb4313c",
   "metadata": {},
   "source": [
    "## 10. 工作流（Workflow）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9016c66a",
   "metadata": {},
   "source": [
    "### 10.1 工作流（Workflow）简介\n",
    "\n",
    "工作流顾名思义是对一些列工作步骤的抽象。\n",
    "\n",
    "LlamaIndex 的工作流是事件（`event`）驱动的：\n",
    "\n",
    "- 工作流由 `step` 组成\n",
    "- 每个 `step` 处理特定的事件\n",
    "- `step` 也会产生新的事件（交由后继的 `step` 进行处理）\n",
    "- 直到产生 `StopEvent` 整个工作流结束\n",
    "\n",
    "LlamaIndex Workflows：https://docs.llamaindex.ai/en/stable/module_guides/workflow/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99b8edc-2764-4f07-ad2e-1e8c549b8157",
   "metadata": {},
   "source": [
    "### 10.2 工作流设计\n",
    "\n",
    "使用自然语言查询数据库，数据库中包含多张表\n",
    "\n",
    "工作流设计：\n",
    "\n",
    "<img src=\"./assets/workflow.png\" alt=\"工作流\" width=\"1000\"/>\n",
    "\n",
    "分步说明：\n",
    "\n",
    "1. 用户输入自然语言查询\n",
    "2. 系统先去检索跟查询相关的表\n",
    "3. 根据表的 Schema 让大模型生成 SQL\n",
    "4. 用生成的 SQL 查询数据库\n",
    "5. 根据查询结果，调用大模型生成自然语言回复"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be28368-98b7-4dcf-8cca-a05f443cb66b",
   "metadata": {},
   "source": [
    "### 10.3 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "id": "eb7487c6-f529-4987-b069-1e96d20303ae",
   "metadata": {},
   "source": [
    "# 下载 WikiTableQuestions\n",
    "# WikiTableQuestions 是一个为表格问答设计的数据集。其中包含 2,108 个从维基百科提取的 HTML 表格\n",
    "\n",
    "# !wget \"https://github.com/ppasupat/WikiTableQuestions/releases/download/v1.0.2/WikiTableQuestions-1.0.2-compact.zip\" -O wiki_data.zip\n",
    "# !unzip wiki_data.zip"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0b7dfdbf-c064-4575-b59e-6562e86aff21",
   "metadata": {},
   "source": [
    "1. 遍历目录加载表格"
   ]
  },
  {
   "cell_type": "code",
   "id": "dd4661dd-856a-4476-b771-1164fecadf47",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"./WikiTableQuestions/csv/200-csv\")\n",
    "csv_files = sorted([f for f in data_dir.glob(\"*.csv\")])\n",
    "dfs = []\n",
    "for csv_file in csv_files:\n",
    "    print(f\"processing file: {csv_file}\")\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {csv_file}: {str(e)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1f7e7eef-d81a-4dd2-bcfd-1fb5dd89603a",
   "metadata": {},
   "source": [
    "2. 为每个表生成一段文字表述（用于检索），保存在 `WikiTableQuestions_TableInfo` 目录"
   ]
  },
  {
   "cell_type": "code",
   "id": "25c1a118-6f5e-470a-bb02-54fd5f1497ce",
   "metadata": {},
   "source": [
    "from llama_index.core.prompts import ChatPromptTemplate\n",
    "from llama_index.core.bridge.pydantic import BaseModel, Field\n",
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "\n",
    "class TableInfo(BaseModel):\n",
    "    \"\"\"Information regarding a structured table.\"\"\"\n",
    "\n",
    "    table_name: str = Field(\n",
    "        ..., description=\"table name (must be underscores and NO spaces)\"\n",
    "    )\n",
    "    table_summary: str = Field(\n",
    "        ..., description=\"short, concise summary/caption of the table\"\n",
    "    )\n",
    "\n",
    "\n",
    "prompt_str = \"\"\"\n",
    "Give me a summary of the table with the following JSON format.\n",
    "\n",
    "- The table name must be unique to the table and describe it while being concise. \n",
    "- Do NOT output a generic table name (e.g. table, my_table).\n",
    "\n",
    "Do NOT make the table name one of the following: {exclude_table_name_list}\n",
    "\n",
    "Table:\n",
    "{table_str}\n",
    "\n",
    "Summary: \"\"\"\n",
    "\n",
    "prompt_tmpl = ChatPromptTemplate(\n",
    "    message_templates=[ChatMessage.from_str(prompt_str, role=\"user\")]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9aaded9f-4af5-4ab9-b994-374ac420bf58",
   "metadata": {},
   "source": [
    "tableinfo_dir = \"WikiTableQuestions_TableInfo\"\n",
    "# !mkdir {tableinfo_dir}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8e4bf4ce-f969-45a2-b705-adc23a0c1cf1",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def _get_tableinfo_with_index(idx: int) -> str:\n",
    "    results_gen = Path(tableinfo_dir).glob(f\"{idx}_*\")\n",
    "    results_list = list(results_gen)\n",
    "    if len(results_list) == 0:\n",
    "        return None\n",
    "    elif len(results_list) == 1:\n",
    "        path = results_list[0]\n",
    "        with open(path, 'r') as file:\n",
    "            data = json.load(file) \n",
    "            return TableInfo.model_validate(data)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"More than one file matching index: {list(results_gen)}\"\n",
    "        )\n",
    "    \n",
    "\n",
    "table_names = set()\n",
    "table_infos = []\n",
    "for idx, df in enumerate(dfs):\n",
    "    table_info = _get_tableinfo_with_index(idx)\n",
    "    if table_info:\n",
    "        table_infos.append(table_info)\n",
    "    else:\n",
    "        while True:\n",
    "            df_str = df.head(10).to_csv()\n",
    "            table_info = llm.structured_predict(\n",
    "                TableInfo,\n",
    "                prompt_tmpl,\n",
    "                table_str=df_str,\n",
    "                exclude_table_name_list=str(list(table_names)),\n",
    "            )\n",
    "            table_name = table_info.table_name\n",
    "            print(f\"Processed table: {table_name}\")\n",
    "            if table_name not in table_names:\n",
    "                table_names.add(table_name)\n",
    "                break\n",
    "            else:\n",
    "                # try again\n",
    "                print(f\"Table name {table_name} already exists, trying again.\")\n",
    "                pass\n",
    "\n",
    "        out_file = f\"{tableinfo_dir}/{idx}_{table_name}.json\"\n",
    "        json.dump(table_info.dict(), open(out_file, \"w\"))\n",
    "    table_infos.append(table_info)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "73345b81-07ff-49b0-9ccd-ed553c195f93",
   "metadata": {},
   "source": [
    "3. 将上述表格存入 SQLite 数据库"
   ]
  },
  {
   "cell_type": "code",
   "id": "09b6fd32-3255-4f2d-9962-eb9449f56565",
   "metadata": {},
   "source": [
    "# put data into sqlite db\n",
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    ")\n",
    "import re\n",
    "\n",
    "\n",
    "# Function to create a sanitized column name\n",
    "def sanitize_column_name(col_name):\n",
    "    # Remove special characters and replace spaces with underscores\n",
    "    return re.sub(r\"\\W+\", \"_\", col_name)\n",
    "\n",
    "\n",
    "# Function to create a table from a DataFrame using SQLAlchemy\n",
    "def create_table_from_dataframe(df: pd.DataFrame, table_name: str, engine, metadata_obj):\n",
    "    # Sanitize column names\n",
    "    sanitized_columns = {col: sanitize_column_name(col) for col in df.columns}\n",
    "    df = df.rename(columns=sanitized_columns)\n",
    "\n",
    "    # Dynamically create columns based on DataFrame columns and data types\n",
    "    columns = [\n",
    "        Column(col, String if dtype == \"object\" else Integer)\n",
    "        for col, dtype in zip(df.columns, df.dtypes)\n",
    "    ]\n",
    "\n",
    "    # Create a table with the defined columns\n",
    "    table = Table(table_name, metadata_obj, *columns)\n",
    "\n",
    "    # Create the table in the database\n",
    "    metadata_obj.create_all(engine)\n",
    "\n",
    "    # Insert data from DataFrame into the table\n",
    "    with engine.connect() as conn:\n",
    "        for _, row in df.iterrows():\n",
    "            insert_stmt = table.insert().values(**row.to_dict())\n",
    "            conn.execute(insert_stmt)\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "# engine = create_engine(\"sqlite:///:memory:\")\n",
    "engine = create_engine(\"sqlite:///wiki_table_questions.db\")\n",
    "metadata_obj = MetaData()\n",
    "for idx, df in enumerate(dfs):\n",
    "    tableinfo = _get_tableinfo_with_index(idx)\n",
    "    print(f\"Creating table: {tableinfo.table_name}\")\n",
    "    create_table_from_dataframe(df, tableinfo.table_name, engine, metadata_obj)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "18b6ab4f-7db7-47ef-ad8a-898b19540d56",
   "metadata": {},
   "source": [
    "### 10.4 构建基础工具"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2ebdd1-88e4-4e3e-b025-000890ac300e",
   "metadata": {},
   "source": [
    "1. 创建基于表的描述的向量索引\n",
    "\n",
    "- `ObjectIndex` 是一个 LlamaIndex 内置的模块，通过索引 (Index）检索任意 Python 对象\n",
    "- 这里我们使用 `VectorStoreIndex` 也就是向量检索，并通过 `SQLTableNodeMapping` 将文本描述的 `node` 和数据库的表形成映射\n",
    "- 相关文档：https://docs.llamaindex.ai/en/stable/examples/objects/object_index/#the-objectindex-class"
   ]
  },
  {
   "cell_type": "code",
   "id": "49e12988-cc89-4618-b3f6-a6a038c3c8dd",
   "metadata": {},
   "source": [
    "import os\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.dashscope import DashScope, DashScopeGenerationModels\n",
    "from llama_index.embeddings.dashscope import DashScopeEmbedding, DashScopeTextEmbeddingModels\n",
    "from llama_index.core.objects import (\n",
    "    SQLTableNodeMapping,\n",
    "    ObjectIndex,\n",
    "    SQLTableSchema,\n",
    ")\n",
    "from llama_index.core import SQLDatabase, VectorStoreIndex\n",
    "\n",
    "# 设置全局模型\n",
    "Settings.llm = DashScope(model_name=DashScopeGenerationModels.QWEN_MAX, api_key=os.getenv(\"DASHSCOPE_API_KEY\"))\n",
    "Settings.embed_model = DashScopeEmbedding(model_name=DashScopeTextEmbeddingModels.TEXT_EMBEDDING_V1)\n",
    "\n",
    "sql_database = SQLDatabase(engine)\n",
    "\n",
    "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
    "table_schema_objs = [\n",
    "    SQLTableSchema(table_name=t.table_name, context_str=t.table_summary)\n",
    "    for t in table_infos\n",
    "]  # add a SQLTableSchema for each table\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    table_schema_objs,\n",
    "    table_node_mapping,\n",
    "    VectorStoreIndex,\n",
    ")\n",
    "obj_retriever = obj_index.as_retriever(similarity_top_k=3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ef92b78b-0530-468d-90ec-309d1614d390",
   "metadata": {},
   "source": [
    "2. 创建 SQL 查询器"
   ]
  },
  {
   "cell_type": "code",
   "id": "948b8bee-2af6-4487-8b27-a2b2a5d7420b",
   "metadata": {},
   "source": [
    "from llama_index.core.retrievers import SQLRetriever\n",
    "from typing import List\n",
    "\n",
    "sql_retriever = SQLRetriever(sql_database)\n",
    "\n",
    "\n",
    "def get_table_context_str(table_schema_objs: List[SQLTableSchema]):\n",
    "    \"\"\"Get table context string.\"\"\"\n",
    "    context_strs = []\n",
    "    for table_schema_obj in table_schema_objs:\n",
    "        table_info = sql_database.get_single_table_info(\n",
    "            table_schema_obj.table_name\n",
    "        )\n",
    "        if table_schema_obj.context_str:\n",
    "            table_opt_context = \" The table description is: \"\n",
    "            table_opt_context += table_schema_obj.context_str\n",
    "            table_info += table_opt_context\n",
    "\n",
    "        context_strs.append(table_info)\n",
    "    return \"\\n\\n\".join(context_strs)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "39d5bac2-4c10-4411-bcd1-d825727df41f",
   "metadata": {},
   "source": [
    "3. 创建 Text2SQL 的提示词（系统默认模板），和输出结果解析器（从生成的文本中抽取SQL）"
   ]
  },
  {
   "cell_type": "code",
   "id": "da0c9ea7-5aa5-4069-8baf-9ca62c9e278a",
   "metadata": {},
   "source": [
    "from llama_index.core.prompts.default_prompts import DEFAULT_TEXT_TO_SQL_PROMPT\n",
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.core.llms import ChatResponse\n",
    "\n",
    "def parse_response_to_sql(chat_response: ChatResponse) -> str:\n",
    "    \"\"\"Parse response to SQL.\"\"\"\n",
    "    response = chat_response.message.content\n",
    "    sql_query_start = response.find(\"SQLQuery:\")\n",
    "    if sql_query_start != -1:\n",
    "        response = response[sql_query_start:]\n",
    "        # TODO: move to removeprefix after Python 3.9+\n",
    "        if response.startswith(\"SQLQuery:\"):\n",
    "            response = response[len(\"SQLQuery:\") :]\n",
    "    sql_result_start = response.find(\"SQLResult:\")\n",
    "    if sql_result_start != -1:\n",
    "        response = response[:sql_result_start]\n",
    "    return response.strip().strip(\"```\").strip()\n",
    "\n",
    "\n",
    "text2sql_prompt = DEFAULT_TEXT_TO_SQL_PROMPT.partial_format(\n",
    "    dialect=engine.dialect.name\n",
    ")\n",
    "print(text2sql_prompt.template)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "691c7cf0-1217-4d16-8196-2937411bbbed",
   "metadata": {},
   "source": [
    "4. 创建自然语言回复生成模板"
   ]
  },
  {
   "cell_type": "code",
   "id": "f1fbf506-9c46-44bd-9148-0712e4e835a9",
   "metadata": {},
   "source": [
    "response_synthesis_prompt_str = (\n",
    "    \"Given an input question, synthesize a response from the query results.\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"SQL: {sql_query}\\n\"\n",
    "    \"SQL Response: {context_str}\\n\"\n",
    "    \"Response: \"\n",
    ")\n",
    "response_synthesis_prompt = PromptTemplate(\n",
    "    response_synthesis_prompt_str,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9f4b9121-7da6-496c-8506-48fee7d4ac5c",
   "metadata": {},
   "source": [
    "llm = DashScope(model_name=DashScopeGenerationModels.QWEN_MAX, api_key=os.getenv(\"DASHSCOPE_API_KEY\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "258cc672-bed9-45b6-a9cd-80d162f96fd1",
   "metadata": {},
   "source": [
    "### 10.5 定义工作流"
   ]
  },
  {
   "cell_type": "code",
   "id": "8ac5f9db-6dc7-4828-bd2b-1ff7d1e16abd",
   "metadata": {},
   "source": [
    "from llama_index.core.workflow import (\n",
    "    Workflow,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    step,\n",
    "    Context,\n",
    "    Event,\n",
    ")\n",
    "\n",
    "# 事件：找到数据库中相关的表\n",
    "class TableRetrieveEvent(Event):\n",
    "    \"\"\"Result of running table retrieval.\"\"\"\n",
    "\n",
    "    table_context_str: str\n",
    "    query: str\n",
    "\n",
    "# 事件：文本转 SQL\n",
    "class TextToSQLEvent(Event):\n",
    "    \"\"\"Text-to-SQL event.\"\"\"\n",
    "\n",
    "    sql: str\n",
    "    query: str\n",
    "\n",
    "\n",
    "class TextToSQLWorkflow1(Workflow):\n",
    "    \"\"\"Text-to-SQL Workflow that does query-time table retrieval.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        obj_retriever,\n",
    "        text2sql_prompt,\n",
    "        sql_retriever,\n",
    "        response_synthesis_prompt,\n",
    "        llm,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.obj_retriever = obj_retriever\n",
    "        self.text2sql_prompt = text2sql_prompt\n",
    "        self.sql_retriever = sql_retriever\n",
    "        self.response_synthesis_prompt = response_synthesis_prompt\n",
    "        self.llm = llm\n",
    "\n",
    "    @step\n",
    "    def retrieve_tables(\n",
    "        self, ctx: Context, ev: StartEvent\n",
    "    ) -> TableRetrieveEvent:\n",
    "        \"\"\"Retrieve tables.\"\"\"\n",
    "        table_schema_objs = self.obj_retriever.retrieve(ev.query)\n",
    "        table_context_str = get_table_context_str(table_schema_objs)\n",
    "        print(\"====\\n\"+table_context_str+\"\\n====\")\n",
    "        return TableRetrieveEvent(\n",
    "            table_context_str=table_context_str, query=ev.query\n",
    "        )\n",
    "\n",
    "    @step\n",
    "    def generate_sql(\n",
    "        self, ctx: Context, ev: TableRetrieveEvent\n",
    "    ) -> TextToSQLEvent:\n",
    "        \"\"\"Generate SQL statement.\"\"\"\n",
    "        fmt_messages = self.text2sql_prompt.format_messages(\n",
    "            query_str=ev.query, schema=ev.table_context_str\n",
    "        )\n",
    "        chat_response = self.llm.chat(fmt_messages)\n",
    "        sql = parse_response_to_sql(chat_response)\n",
    "        print(\"====\\n\"+sql+\"\\n====\")\n",
    "        return TextToSQLEvent(sql=sql, query=ev.query)\n",
    "\n",
    "    @step\n",
    "    def generate_response(self, ctx: Context, ev: TextToSQLEvent) -> StopEvent:\n",
    "        \"\"\"Run SQL retrieval and generate response.\"\"\"\n",
    "        retrieved_rows = self.sql_retriever.retrieve(ev.sql)\n",
    "        print(\"====\\n\"+str(retrieved_rows)+\"\\n====\")\n",
    "        fmt_messages = self.response_synthesis_prompt.format_messages(\n",
    "            sql_query=ev.sql,\n",
    "            context_str=str(retrieved_rows),\n",
    "            query_str=ev.query,\n",
    "        )\n",
    "        chat_response = llm.chat(fmt_messages)\n",
    "        return StopEvent(result=chat_response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9b3060a2-20e4-4153-b3f9-6b91ed4d7020",
   "metadata": {},
   "source": [
    "workflow = TextToSQLWorkflow1(\n",
    "    obj_retriever,\n",
    "    text2sql_prompt,\n",
    "    sql_retriever,\n",
    "    response_synthesis_prompt,\n",
    "    llm,\n",
    "    verbose=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ead701cd-c79d-4b48-8a20-9c2322140712",
   "metadata": {},
   "source": [
    "response = await workflow.run(\n",
    "    query=\"What was the year that The Notorious B.I.G was signed to Bad Boy?\"\n",
    ")\n",
    "print(str(response))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "09b64fac-b8b8-4fad-8ecc-5a9431469706",
   "metadata": {},
   "source": [
    "### 10.6 可视化工作流"
   ]
  },
  {
   "cell_type": "code",
   "id": "8b370ab8-9c87-4baa-92ba-3e729a481857",
   "metadata": {},
   "source": [
    "# !pip install llama-index-utils-workflow"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "933d00bd-a602-4958-bed3-d1b530192895",
   "metadata": {},
   "source": [
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "\n",
    "draw_all_possible_flows(\n",
    "    TextToSQLWorkflow1, filename=\"text_to_sql_table_retrieval.html\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "78fc8317-0cac-458b-9ee5-969e4b46442c",
   "metadata": {},
   "source": [
    "### 10.7 工作流管理框架意义是什么\n",
    "\n",
    "思考以下情况：\n",
    "\n",
    "- `step` 的执行顺序有逻辑分支\n",
    "- `step` 的执行有循环\n",
    "- `step` 的执行可以并行\n",
    "- 一个 `step` 的触发条件依赖前面若干 `step` 的结果，且它们之间可能有循环或者并行\n",
    "\n",
    "<img src=\"./assets/workflow2.png\" alt=\"工作流举例\" width=\"800\"/>\n",
    "\n",
    "所以，工作流管理框架的意思是便于将单个事件的处理逻辑和事件之间的执行顺序独立开\n",
    "\n",
    "关于 LlamaIndex 工作流的更详细文档：https://docs.llamaindex.ai/en/stable/examples/workflow/workflows_cookbook/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c98c0-6636-4d71-9156-731e7ca28b6f",
   "metadata": {},
   "source": [
    "## 11. LlamaIndex 的更多功能\n",
    "\n",
    "- 智能体（Agent）开发框架：https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/\n",
    "- RAG 的评测：https://docs.llamaindex.ai/en/stable/module_guides/evaluating/\n",
    "- 过程监控：https://docs.llamaindex.ai/en/stable/module_guides/observability/\n",
    "\n",
    "以上内容涉及较多背景知识，暂时不在本课展开，相关知识会在后面课程中逐一详细讲解。\n",
    "\n",
    "此外，LlamaIndex 针对生产级的 RAG 系统中遇到的各个方面的细节问题，总结了很多高端技巧（[Advanced Topics](https://docs.llamaindex.ai/en/stable/optimizing/production_rag/)），对实战很有参考价值，非常推荐有能力的同学阅读。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e9b8c6",
   "metadata": {},
   "source": [
    "## 12. 学习打卡\n",
    "\n",
    "1. 掌握 LlamaIndex 框架核心模块\n",
    "2. 熟练使用 LlamaIndex 高效开发一个贴合自己需求的RAG系统\n",
    "3. 理解 LlamaIndex 中的工作流（Workflow）实现\n",
    "4. 结合自己的业务场景，通过NL2SQL技术来实现一个功能"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
