{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82f69aa5-a44d-4bff-8869-a553c924837d",
   "metadata": {},
   "source": [
    "# 第6章 LangGraph 开发基础\n",
    "\n",
    "## 💡 学习目标\n",
    "\n",
    "1. 掌握 LangGraph 的核心概念和使用场景\n",
    "2. 掌握 LangGraph 的基本用法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811f358b-3f4b-4b57-b0de-c453af44553e",
   "metadata": {},
   "source": [
    "## 1. LangGraph 介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9537410-180c-421e-b395-8ec6f41daa6f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.1 基本概述\n",
    "\n",
    "LangGraph 是由 LangChain 团队开发的一个开源框架，旨在帮助开发者构建基于大型语言模型（LLM）的复杂、有状态、多主体的应用。它通过将工作流表示为图结构（graph），提供了更高的灵活性和控制能力，特别适合需要循环逻辑、状态管理以及多主体协作的场景，比如智能代理（agent）和多代理工作流。\n",
    "\n",
    "LangGraph 是为智能体和工作流设计一套底层编排框架\n",
    "\n",
    "官方文档：https://langchain-ai.github.io/langgraph/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24dfea2-3c01-42b4-a312-8786a3902593",
   "metadata": {},
   "source": [
    "### 1.2 核心概念\n",
    "\n",
    "**图结构（Graph Structure）**\n",
    "\n",
    "LangGraph 将应用逻辑组织成一个有向图，其中：\n",
    "\n",
    "- 节点（Nodes）：代表具体的操作或计算步骤，可以是调用语言模型、执行函数或与外部工具交互等\n",
    "- 边（Edges）：定义节点之间的连接和执行顺序，支持普通边（直接连接）和条件边（基于条件动态选择下一步）\n",
    "\n",
    "**状态管理（State Management）**\n",
    "\n",
    "LangGraph 的核心特点是自动维护和管理状态\n",
    "\n",
    "状态（State）是一个贯穿整个图的共享数据结构，记录了应用运行过程中的上下文信息\n",
    "\n",
    "每个节点可以根据当前状态执行任务并更新状态，确保系统在多步骤或多主体交互中保持一致性\n",
    "\n",
    "**循环能力（Cyclical Workflows）**\n",
    "\n",
    "与传统的线性工作流（如 LangChain 的 LCEL）不同，LangGraph 支持循环逻辑，这使得它非常适合需要反复推理、决策或与用户交互的代理应用。例如，一个代理可以在循环中不断调用语言模型，直到达成目标。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67959ee-6b88-4ef1-9b09-f6df5e07abd6",
   "metadata": {},
   "source": [
    "### 1.3 主要特点\n",
    "\n",
    "**灵活性：** 开发者可以精细控制工作流的逻辑和状态更新，适应复杂的业务需求            \n",
    "**持久性：** 内置支持状态的保存和恢复，便于错误恢复和长时间运行的任务             \n",
    "**多主体协作：** 允许多个代理协同工作，每个代理负责特定任务，通过图结构协调交互             \n",
    "**工具集成：** 可以轻松集成外部工具（如搜索API）或自定义函数，增强代理能力           \n",
    "**人性化交互：** 支持“人在回路”（human-in-the-loop）功能，让人类在关键步骤参与决策"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa3ea46-3bd1-497d-b45d-97e3d64e9792",
   "metadata": {},
   "source": [
    "### 1.4 使用场景\n",
    "\n",
    "LangGraph 特别适用于以下场景： \n",
    "\n",
    "**对话代理：** 构建能够记住上下文、动态调整策略的智能聊天机器人             \n",
    "**多步骤任务：** 处理需要分解为多个阶段的复杂问题，如研究、写作或数据分析                \n",
    "**多代理系统：** 协调多个代理分工合作，比如一个负责搜索信息、另一个负责总结内容的系统"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33d6c63-6c72-4802-81fa-5d47d12df99e",
   "metadata": {},
   "source": [
    "### 1.5 与 LangChain 的关系\n",
    "\n",
    "- LangGraph 是 LangChain 生态的一部分，但它是独立于 LangChain 的一个模块             \n",
    "- LangChain 更擅长处理简单的线性任务链（DAG），而 LangGraph 专注于更复杂的循环和多主体场景           \n",
    "- 你可以单独使用 LangGraph，也可以结合 LangChain 的组件（如提示模板、工具接口）来增强功能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b226cfb-388f-4a47-b098-fed931622b8f",
   "metadata": {},
   "source": [
    "## 2. 实现一个带上下文的 Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c23eac-d084-40a6-97ee-13c5917b16bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638c1f53-d916-4fe4-b1c7-c9f7fb8b533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# 定义 State\n",
    "class State(TypedDict):\n",
    "    # 状态变量 messages 类型是 list，更新方式是 add_messages\n",
    "    # add_messages 是内置的一个方法，将新的消息列表追加在原列表后面\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# 创建 Graph\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ddd992-c13c-4689-a011-eaa1c391959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "\n",
    "# 定义一个执行节点\n",
    "# 输入是 State，输出是系统回复\n",
    "def chatbot(state: State):\n",
    "    # 调用大模型，并返回消息（列表）\n",
    "    # 返回值会触发状态更新 add_messages\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b75a6-b418-4dd9-85bd-8d16839893d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# 可视化展示这个工作流\n",
    "try:\n",
    "    display(Image(data=graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33df99d-0fb7-43d4-9063-bd260cc6ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage \n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    # 向 graph 传入一条消息（触发状态更新 add_messages）\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            if \"messages\" in value and isinstance(value[\"messages\"][-1], AIMessage):\n",
    "                print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "def run():\n",
    "    # 执行这个工作流\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.strip() == \"\":\n",
    "            break\n",
    "    \n",
    "        stream_graph_updates(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303ddc18-282c-418f-81c7-7ba6d18ddbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4394dc95-df55-4128-ad17-f192e401aecc",
   "metadata": {},
   "source": [
    "## 3. 实现RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec9703a-e9c2-4599-94e8-fef742c66356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain-community pymupdf\n",
    "# !pip install dashscope\n",
    "# !pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6117e0-6725-4e1d-bd24-4581d44561b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# 加载文档\n",
    "loader = PyMuPDFLoader(\"./data/deepseek-v3-1-4.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "# 文档切分\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents(\n",
    "    [page.page_content for page in pages[:2]]\n",
    ")\n",
    "\n",
    "# 灌库\n",
    "embeddings = DashScopeEmbeddings(model=\"text-embedding-v1\")\n",
    "db = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "# 检索 top-5 结果\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc1cb4c-d4fe-40fb-9933-8b544e6dbf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# Prompt模板\n",
    "template = \"\"\"请根据对话历史和下面提供的信息回答上面用户提出的问题:\n",
    "{query}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        HumanMessagePromptTemplate.from_template(template),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbebe52-2b78-483b-a0a6-108b8ddea52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval(state: State):\n",
    "    user_query = \"\"\n",
    "    if len(state[\"messages\"]) >= 1:\n",
    "        # 获取最后一轮用户输入\n",
    "        user_query = state[\"messages\"][-1]\n",
    "    else:\n",
    "        return {\"messages\": []}\n",
    "    # 检索\n",
    "    docs = retriever.invoke(str(user_query))\n",
    "    # 填 prompt 模板\n",
    "    messages = prompt.invoke(\"\\n\".join([doc.page_content for doc in docs])).messages\n",
    "    return {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9375d8ed-df6c-451f-b5dd-e7dbaf8bd589",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"retrieval\", retrieval)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_edge(START, \"retrieval\")\n",
    "graph_builder.add_edge(\"retrieval\",\"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1cebfa-64b7-4468-a327-dcaf37ebdd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# 可视化展示这个工作流\n",
    "try:\n",
    "    display(Image(data=graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c706098a-a08a-4e32-a79a-ba0371902016",
   "metadata": {},
   "outputs": [],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa9d102-f321-4a13-a3e5-9771e28687ba",
   "metadata": {},
   "source": [
    "## 4. 加入分支：若找不到答案则转人工处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e7df4d-6ab4-4377-810a-60b882a955c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "from typing import Literal\n",
    "from langgraph.types import interrupt, Command\n",
    "\n",
    "# 校验\n",
    "def verify(state: State)-> Literal[\"chatbot\",\"ask_human\"]:\n",
    "    message = HumanMessage(\"请根据对话历史和上面提供的信息判断，已知的信息是否能够回答用户的问题。直接输出你的判断'Y'或'N'\")\n",
    "    ret = llm.invoke(state[\"messages\"]+[message])\n",
    "    if 'Y' in ret.content:\n",
    "        return \"chatbot\"\n",
    "    else:\n",
    "        return \"ask_human\"\n",
    "\n",
    "# 人工处理\n",
    "def ask_human(state: State):\n",
    "    user_query = state[\"messages\"][-2].content\n",
    "    human_response = interrupt(\n",
    "       {\n",
    "          \"question\": user_query\n",
    "       }\n",
    "    )\n",
    "    # Update the state with the human's input or route the graph based on the input.\n",
    "    return {\n",
    "        \"messages\": [AIMessage(human_response)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d60dd8c-a0af-4947-9a8d-4110621a2a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 用于持久化存储 state (这里以内存模拟）\n",
    "# 生产中可以使用 Redis 等高性能缓存中间件\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"retrieval\", retrieval)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"ask_human\", ask_human)\n",
    "\n",
    "graph_builder.add_edge(START, \"retrieval\")\n",
    "graph_builder.add_conditional_edges(\"retrieval\", verify)\n",
    "graph_builder.add_edge(\"ask_human\", END)\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# 中途会被转人工打断，所以需要 checkpointer 存储状态\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11ae5c5-2aa7-4d5c-b650-f276b6730d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage \n",
    "\n",
    "# 当使用 checkpointer 时，需要配置读取 state 的 thread_id\n",
    "# 可以类比 OpenAI Assistants API 理解，或者想象 Redis 中的 key \n",
    "thread_config = {\"configurable\": {\"thread_id\": \"my_thread_id\"}}\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    # 向 graph 传入一条消息（触发状态更新 add_messages）\n",
    "    for event in graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        thread_config\n",
    "    ):\n",
    "        for value in event.values():\n",
    "            if isinstance(value, tuple):\n",
    "                return value[0].value[\"question\"]\n",
    "            elif \"messages\" in value and isinstance(value[\"messages\"][-1], AIMessage):\n",
    "                print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "                return None\n",
    "    return None\n",
    "\n",
    "def resume_graph_updates(human_input: str):\n",
    "    for event in graph.stream(\n",
    "        Command(resume=human_input), thread_config, stream_mode=\"updates\"\n",
    "    ):\n",
    "        for value in event.values():\n",
    "            if \"messages\" in value and isinstance(value[\"messages\"][-1], AIMessage):\n",
    "                print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "def run():\n",
    "    # 执行这个工作流\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.strip() == \"\":\n",
    "            break\n",
    "        question = stream_graph_updates(user_input)\n",
    "        if question:\n",
    "            human_answer = input(\"Ask Human: \"+question+\"\\nHuman: \")\n",
    "            resume_graph_updates(human_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183de00b-6b31-4e62-9687-1ee6fc5fefd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbec292-3759-430d-a6dd-d981a17e11e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# 可视化展示这个工作流\n",
    "try:\n",
    "    display(Image(data=graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1db9e3-eb01-4723-a7ea-2ec24d9e8519",
   "metadata": {},
   "source": [
    "LangGraph 还支持：\n",
    "\n",
    "- 工具调用\n",
    "- 并行处理\n",
    "- 状态持久化\n",
    "- 对话历史管理\n",
    "- 历史动作回放（用于调试与测试）\n",
    "- 子图管理\n",
    "- 多智能体协作\n",
    "- ...\n",
    "  \n",
    "更多关于 LangGraph 的 HowTo，参考官方文档：https://langchain-ai.github.io/langgraph/how-tos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48ddc3b-210e-4858-8632-4733d6c150fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
