{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82f69aa5-a44d-4bff-8869-a553c924837d",
   "metadata": {},
   "source": [
    "# ç¬¬6ç«  LangGraph å¼€å‘åŸºç¡€\n",
    "\n",
    "## ğŸ’¡ å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "1. æŒæ¡ LangGraph çš„æ ¸å¿ƒæ¦‚å¿µå’Œä½¿ç”¨åœºæ™¯\n",
    "2. æŒæ¡ LangGraph çš„åŸºæœ¬ç”¨æ³•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811f358b-3f4b-4b57-b0de-c453af44553e",
   "metadata": {},
   "source": [
    "## 1. LangGraph ä»‹ç»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9537410-180c-421e-b395-8ec6f41daa6f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.1 åŸºæœ¬æ¦‚è¿°\n",
    "\n",
    "LangGraph æ˜¯ç”± LangChain å›¢é˜Ÿå¼€å‘çš„ä¸€ä¸ªå¼€æºæ¡†æ¶ï¼Œæ—¨åœ¨å¸®åŠ©å¼€å‘è€…æ„å»ºåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤æ‚ã€æœ‰çŠ¶æ€ã€å¤šä¸»ä½“çš„åº”ç”¨ã€‚å®ƒé€šè¿‡å°†å·¥ä½œæµè¡¨ç¤ºä¸ºå›¾ç»“æ„ï¼ˆgraphï¼‰ï¼Œæä¾›äº†æ›´é«˜çš„çµæ´»æ€§å’Œæ§åˆ¶èƒ½åŠ›ï¼Œç‰¹åˆ«é€‚åˆéœ€è¦å¾ªç¯é€»è¾‘ã€çŠ¶æ€ç®¡ç†ä»¥åŠå¤šä¸»ä½“åä½œçš„åœºæ™¯ï¼Œæ¯”å¦‚æ™ºèƒ½ä»£ç†ï¼ˆagentï¼‰å’Œå¤šä»£ç†å·¥ä½œæµã€‚\n",
    "\n",
    "LangGraph æ˜¯ä¸ºæ™ºèƒ½ä½“å’Œå·¥ä½œæµè®¾è®¡ä¸€å¥—åº•å±‚ç¼–æ’æ¡†æ¶\n",
    "\n",
    "å®˜æ–¹æ–‡æ¡£ï¼šhttps://langchain-ai.github.io/langgraph/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24dfea2-3c01-42b4-a312-8786a3902593",
   "metadata": {},
   "source": [
    "### 1.2 æ ¸å¿ƒæ¦‚å¿µ\n",
    "\n",
    "**å›¾ç»“æ„ï¼ˆGraph Structureï¼‰**\n",
    "\n",
    "LangGraph å°†åº”ç”¨é€»è¾‘ç»„ç»‡æˆä¸€ä¸ªæœ‰å‘å›¾ï¼Œå…¶ä¸­ï¼š\n",
    "\n",
    "- èŠ‚ç‚¹ï¼ˆNodesï¼‰ï¼šä»£è¡¨å…·ä½“çš„æ“ä½œæˆ–è®¡ç®—æ­¥éª¤ï¼Œå¯ä»¥æ˜¯è°ƒç”¨è¯­è¨€æ¨¡å‹ã€æ‰§è¡Œå‡½æ•°æˆ–ä¸å¤–éƒ¨å·¥å…·äº¤äº’ç­‰\n",
    "- è¾¹ï¼ˆEdgesï¼‰ï¼šå®šä¹‰èŠ‚ç‚¹ä¹‹é—´çš„è¿æ¥å’Œæ‰§è¡Œé¡ºåºï¼Œæ”¯æŒæ™®é€šè¾¹ï¼ˆç›´æ¥è¿æ¥ï¼‰å’Œæ¡ä»¶è¾¹ï¼ˆåŸºäºæ¡ä»¶åŠ¨æ€é€‰æ‹©ä¸‹ä¸€æ­¥ï¼‰\n",
    "\n",
    "**çŠ¶æ€ç®¡ç†ï¼ˆState Managementï¼‰**\n",
    "\n",
    "LangGraph çš„æ ¸å¿ƒç‰¹ç‚¹æ˜¯è‡ªåŠ¨ç»´æŠ¤å’Œç®¡ç†çŠ¶æ€\n",
    "\n",
    "çŠ¶æ€ï¼ˆStateï¼‰æ˜¯ä¸€ä¸ªè´¯ç©¿æ•´ä¸ªå›¾çš„å…±äº«æ•°æ®ç»“æ„ï¼Œè®°å½•äº†åº”ç”¨è¿è¡Œè¿‡ç¨‹ä¸­çš„ä¸Šä¸‹æ–‡ä¿¡æ¯\n",
    "\n",
    "æ¯ä¸ªèŠ‚ç‚¹å¯ä»¥æ ¹æ®å½“å‰çŠ¶æ€æ‰§è¡Œä»»åŠ¡å¹¶æ›´æ–°çŠ¶æ€ï¼Œç¡®ä¿ç³»ç»Ÿåœ¨å¤šæ­¥éª¤æˆ–å¤šä¸»ä½“äº¤äº’ä¸­ä¿æŒä¸€è‡´æ€§\n",
    "\n",
    "**å¾ªç¯èƒ½åŠ›ï¼ˆCyclical Workflowsï¼‰**\n",
    "\n",
    "ä¸ä¼ ç»Ÿçš„çº¿æ€§å·¥ä½œæµï¼ˆå¦‚ LangChain çš„ LCELï¼‰ä¸åŒï¼ŒLangGraph æ”¯æŒå¾ªç¯é€»è¾‘ï¼Œè¿™ä½¿å¾—å®ƒéå¸¸é€‚åˆéœ€è¦åå¤æ¨ç†ã€å†³ç­–æˆ–ä¸ç”¨æˆ·äº¤äº’çš„ä»£ç†åº”ç”¨ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªä»£ç†å¯ä»¥åœ¨å¾ªç¯ä¸­ä¸æ–­è°ƒç”¨è¯­è¨€æ¨¡å‹ï¼Œç›´åˆ°è¾¾æˆç›®æ ‡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67959ee-6b88-4ef1-9b09-f6df5e07abd6",
   "metadata": {},
   "source": [
    "### 1.3 ä¸»è¦ç‰¹ç‚¹\n",
    "\n",
    "**çµæ´»æ€§ï¼š** å¼€å‘è€…å¯ä»¥ç²¾ç»†æ§åˆ¶å·¥ä½œæµçš„é€»è¾‘å’ŒçŠ¶æ€æ›´æ–°ï¼Œé€‚åº”å¤æ‚çš„ä¸šåŠ¡éœ€æ±‚            \n",
    "**æŒä¹…æ€§ï¼š** å†…ç½®æ”¯æŒçŠ¶æ€çš„ä¿å­˜å’Œæ¢å¤ï¼Œä¾¿äºé”™è¯¯æ¢å¤å’Œé•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡             \n",
    "**å¤šä¸»ä½“åä½œï¼š** å…è®¸å¤šä¸ªä»£ç†ååŒå·¥ä½œï¼Œæ¯ä¸ªä»£ç†è´Ÿè´£ç‰¹å®šä»»åŠ¡ï¼Œé€šè¿‡å›¾ç»“æ„åè°ƒäº¤äº’             \n",
    "**å·¥å…·é›†æˆï¼š** å¯ä»¥è½»æ¾é›†æˆå¤–éƒ¨å·¥å…·ï¼ˆå¦‚æœç´¢APIï¼‰æˆ–è‡ªå®šä¹‰å‡½æ•°ï¼Œå¢å¼ºä»£ç†èƒ½åŠ›           \n",
    "**äººæ€§åŒ–äº¤äº’ï¼š** æ”¯æŒâ€œäººåœ¨å›è·¯â€ï¼ˆhuman-in-the-loopï¼‰åŠŸèƒ½ï¼Œè®©äººç±»åœ¨å…³é”®æ­¥éª¤å‚ä¸å†³ç­–"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa3ea46-3bd1-497d-b45d-97e3d64e9792",
   "metadata": {},
   "source": [
    "### 1.4 ä½¿ç”¨åœºæ™¯\n",
    "\n",
    "LangGraph ç‰¹åˆ«é€‚ç”¨äºä»¥ä¸‹åœºæ™¯ï¼š \n",
    "\n",
    "**å¯¹è¯ä»£ç†ï¼š** æ„å»ºèƒ½å¤Ÿè®°ä½ä¸Šä¸‹æ–‡ã€åŠ¨æ€è°ƒæ•´ç­–ç•¥çš„æ™ºèƒ½èŠå¤©æœºå™¨äºº             \n",
    "**å¤šæ­¥éª¤ä»»åŠ¡ï¼š** å¤„ç†éœ€è¦åˆ†è§£ä¸ºå¤šä¸ªé˜¶æ®µçš„å¤æ‚é—®é¢˜ï¼Œå¦‚ç ”ç©¶ã€å†™ä½œæˆ–æ•°æ®åˆ†æ                \n",
    "**å¤šä»£ç†ç³»ç»Ÿï¼š** åè°ƒå¤šä¸ªä»£ç†åˆ†å·¥åˆä½œï¼Œæ¯”å¦‚ä¸€ä¸ªè´Ÿè´£æœç´¢ä¿¡æ¯ã€å¦ä¸€ä¸ªè´Ÿè´£æ€»ç»“å†…å®¹çš„ç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33d6c63-6c72-4802-81fa-5d47d12df99e",
   "metadata": {},
   "source": [
    "### 1.5 ä¸ LangChain çš„å…³ç³»\n",
    "\n",
    "- LangGraph æ˜¯ LangChain ç”Ÿæ€çš„ä¸€éƒ¨åˆ†ï¼Œä½†å®ƒæ˜¯ç‹¬ç«‹äº LangChain çš„ä¸€ä¸ªæ¨¡å—             \n",
    "- LangChain æ›´æ“…é•¿å¤„ç†ç®€å•çš„çº¿æ€§ä»»åŠ¡é“¾ï¼ˆDAGï¼‰ï¼Œè€Œ LangGraph ä¸“æ³¨äºæ›´å¤æ‚çš„å¾ªç¯å’Œå¤šä¸»ä½“åœºæ™¯           \n",
    "- ä½ å¯ä»¥å•ç‹¬ä½¿ç”¨ LangGraphï¼Œä¹Ÿå¯ä»¥ç»“åˆ LangChain çš„ç»„ä»¶ï¼ˆå¦‚æç¤ºæ¨¡æ¿ã€å·¥å…·æ¥å£ï¼‰æ¥å¢å¼ºåŠŸèƒ½"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b226cfb-388f-4a47-b098-fed931622b8f",
   "metadata": {},
   "source": [
    "## 2. å®ç°ä¸€ä¸ªå¸¦ä¸Šä¸‹æ–‡çš„ Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c23eac-d084-40a6-97ee-13c5917b16bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638c1f53-d916-4fe4-b1c7-c9f7fb8b533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# å®šä¹‰ State\n",
    "class State(TypedDict):\n",
    "    # çŠ¶æ€å˜é‡ messages ç±»å‹æ˜¯ listï¼Œæ›´æ–°æ–¹å¼æ˜¯ add_messages\n",
    "    # add_messages æ˜¯å†…ç½®çš„ä¸€ä¸ªæ–¹æ³•ï¼Œå°†æ–°çš„æ¶ˆæ¯åˆ—è¡¨è¿½åŠ åœ¨åŸåˆ—è¡¨åé¢\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# åˆ›å»º Graph\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ddd992-c13c-4689-a011-eaa1c391959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹\n",
    "# è¾“å…¥æ˜¯ Stateï¼Œè¾“å‡ºæ˜¯ç³»ç»Ÿå›å¤\n",
    "def chatbot(state: State):\n",
    "    # è°ƒç”¨å¤§æ¨¡å‹ï¼Œå¹¶è¿”å›æ¶ˆæ¯ï¼ˆåˆ—è¡¨ï¼‰\n",
    "    # è¿”å›å€¼ä¼šè§¦å‘çŠ¶æ€æ›´æ–° add_messages\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b75a6-b418-4dd9-85bd-8d16839893d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# å¯è§†åŒ–å±•ç¤ºè¿™ä¸ªå·¥ä½œæµ\n",
    "try:\n",
    "    display(Image(data=graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33df99d-0fb7-43d4-9063-bd260cc6ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage \n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    # å‘ graph ä¼ å…¥ä¸€æ¡æ¶ˆæ¯ï¼ˆè§¦å‘çŠ¶æ€æ›´æ–° add_messagesï¼‰\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            if \"messages\" in value and isinstance(value[\"messages\"][-1], AIMessage):\n",
    "                print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "def run():\n",
    "    # æ‰§è¡Œè¿™ä¸ªå·¥ä½œæµ\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.strip() == \"\":\n",
    "            break\n",
    "    \n",
    "        stream_graph_updates(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303ddc18-282c-418f-81c7-7ba6d18ddbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4394dc95-df55-4128-ad17-f192e401aecc",
   "metadata": {},
   "source": [
    "## 3. å®ç°RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec9703a-e9c2-4599-94e8-fef742c66356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain-community pymupdf\n",
    "# !pip install dashscope\n",
    "# !pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6117e0-6725-4e1d-bd24-4581d44561b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# åŠ è½½æ–‡æ¡£\n",
    "loader = PyMuPDFLoader(\"./data/deepseek-v3-1-4.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "# æ–‡æ¡£åˆ‡åˆ†\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents(\n",
    "    [page.page_content for page in pages[:2]]\n",
    ")\n",
    "\n",
    "# çŒåº“\n",
    "embeddings = DashScopeEmbeddings(model=\"text-embedding-v1\")\n",
    "db = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "# æ£€ç´¢ top-5 ç»“æœ\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc1cb4c-d4fe-40fb-9933-8b544e6dbf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# Promptæ¨¡æ¿\n",
    "template = \"\"\"è¯·æ ¹æ®å¯¹è¯å†å²å’Œä¸‹é¢æä¾›çš„ä¿¡æ¯å›ç­”ä¸Šé¢ç”¨æˆ·æå‡ºçš„é—®é¢˜:\n",
    "{query}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        HumanMessagePromptTemplate.from_template(template),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbebe52-2b78-483b-a0a6-108b8ddea52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval(state: State):\n",
    "    user_query = \"\"\n",
    "    if len(state[\"messages\"]) >= 1:\n",
    "        # è·å–æœ€åä¸€è½®ç”¨æˆ·è¾“å…¥\n",
    "        user_query = state[\"messages\"][-1]\n",
    "    else:\n",
    "        return {\"messages\": []}\n",
    "    # æ£€ç´¢\n",
    "    docs = retriever.invoke(str(user_query))\n",
    "    # å¡« prompt æ¨¡æ¿\n",
    "    messages = prompt.invoke(\"\\n\".join([doc.page_content for doc in docs])).messages\n",
    "    return {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9375d8ed-df6c-451f-b5dd-e7dbaf8bd589",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"retrieval\", retrieval)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_edge(START, \"retrieval\")\n",
    "graph_builder.add_edge(\"retrieval\",\"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1cebfa-64b7-4468-a327-dcaf37ebdd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# å¯è§†åŒ–å±•ç¤ºè¿™ä¸ªå·¥ä½œæµ\n",
    "try:\n",
    "    display(Image(data=graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c706098a-a08a-4e32-a79a-ba0371902016",
   "metadata": {},
   "outputs": [],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa9d102-f321-4a13-a3e5-9771e28687ba",
   "metadata": {},
   "source": [
    "## 4. åŠ å…¥åˆ†æ”¯ï¼šè‹¥æ‰¾ä¸åˆ°ç­”æ¡ˆåˆ™è½¬äººå·¥å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e7df4d-6ab4-4377-810a-60b882a955c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "from typing import Literal\n",
    "from langgraph.types import interrupt, Command\n",
    "\n",
    "# æ ¡éªŒ\n",
    "def verify(state: State)-> Literal[\"chatbot\",\"ask_human\"]:\n",
    "    message = HumanMessage(\"è¯·æ ¹æ®å¯¹è¯å†å²å’Œä¸Šé¢æä¾›çš„ä¿¡æ¯åˆ¤æ–­ï¼Œå·²çŸ¥çš„ä¿¡æ¯æ˜¯å¦èƒ½å¤Ÿå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚ç›´æ¥è¾“å‡ºä½ çš„åˆ¤æ–­'Y'æˆ–'N'\")\n",
    "    ret = llm.invoke(state[\"messages\"]+[message])\n",
    "    if 'Y' in ret.content:\n",
    "        return \"chatbot\"\n",
    "    else:\n",
    "        return \"ask_human\"\n",
    "\n",
    "# äººå·¥å¤„ç†\n",
    "def ask_human(state: State):\n",
    "    user_query = state[\"messages\"][-2].content\n",
    "    human_response = interrupt(\n",
    "       {\n",
    "          \"question\": user_query\n",
    "       }\n",
    "    )\n",
    "    # Update the state with the human's input or route the graph based on the input.\n",
    "    return {\n",
    "        \"messages\": [AIMessage(human_response)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d60dd8c-a0af-4947-9a8d-4110621a2a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# ç”¨äºæŒä¹…åŒ–å­˜å‚¨ state (è¿™é‡Œä»¥å†…å­˜æ¨¡æ‹Ÿï¼‰\n",
    "# ç”Ÿäº§ä¸­å¯ä»¥ä½¿ç”¨ Redis ç­‰é«˜æ€§èƒ½ç¼“å­˜ä¸­é—´ä»¶\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"retrieval\", retrieval)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"ask_human\", ask_human)\n",
    "\n",
    "graph_builder.add_edge(START, \"retrieval\")\n",
    "graph_builder.add_conditional_edges(\"retrieval\", verify)\n",
    "graph_builder.add_edge(\"ask_human\", END)\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# ä¸­é€”ä¼šè¢«è½¬äººå·¥æ‰“æ–­ï¼Œæ‰€ä»¥éœ€è¦ checkpointer å­˜å‚¨çŠ¶æ€\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11ae5c5-2aa7-4d5c-b650-f276b6730d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage \n",
    "\n",
    "# å½“ä½¿ç”¨ checkpointer æ—¶ï¼Œéœ€è¦é…ç½®è¯»å– state çš„ thread_id\n",
    "# å¯ä»¥ç±»æ¯” OpenAI Assistants API ç†è§£ï¼Œæˆ–è€…æƒ³è±¡ Redis ä¸­çš„ key \n",
    "thread_config = {\"configurable\": {\"thread_id\": \"my_thread_id\"}}\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    # å‘ graph ä¼ å…¥ä¸€æ¡æ¶ˆæ¯ï¼ˆè§¦å‘çŠ¶æ€æ›´æ–° add_messagesï¼‰\n",
    "    for event in graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        thread_config\n",
    "    ):\n",
    "        for value in event.values():\n",
    "            if isinstance(value, tuple):\n",
    "                return value[0].value[\"question\"]\n",
    "            elif \"messages\" in value and isinstance(value[\"messages\"][-1], AIMessage):\n",
    "                print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "                return None\n",
    "    return None\n",
    "\n",
    "def resume_graph_updates(human_input: str):\n",
    "    for event in graph.stream(\n",
    "        Command(resume=human_input), thread_config, stream_mode=\"updates\"\n",
    "    ):\n",
    "        for value in event.values():\n",
    "            if \"messages\" in value and isinstance(value[\"messages\"][-1], AIMessage):\n",
    "                print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "def run():\n",
    "    # æ‰§è¡Œè¿™ä¸ªå·¥ä½œæµ\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.strip() == \"\":\n",
    "            break\n",
    "        question = stream_graph_updates(user_input)\n",
    "        if question:\n",
    "            human_answer = input(\"Ask Human: \"+question+\"\\nHuman: \")\n",
    "            resume_graph_updates(human_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183de00b-6b31-4e62-9687-1ee6fc5fefd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbec292-3759-430d-a6dd-d981a17e11e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# å¯è§†åŒ–å±•ç¤ºè¿™ä¸ªå·¥ä½œæµ\n",
    "try:\n",
    "    display(Image(data=graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1db9e3-eb01-4723-a7ea-2ec24d9e8519",
   "metadata": {},
   "source": [
    "LangGraph è¿˜æ”¯æŒï¼š\n",
    "\n",
    "- å·¥å…·è°ƒç”¨\n",
    "- å¹¶è¡Œå¤„ç†\n",
    "- çŠ¶æ€æŒä¹…åŒ–\n",
    "- å¯¹è¯å†å²ç®¡ç†\n",
    "- å†å²åŠ¨ä½œå›æ”¾ï¼ˆç”¨äºè°ƒè¯•ä¸æµ‹è¯•ï¼‰\n",
    "- å­å›¾ç®¡ç†\n",
    "- å¤šæ™ºèƒ½ä½“åä½œ\n",
    "- ...\n",
    "  \n",
    "æ›´å¤šå…³äº LangGraph çš„ HowToï¼Œå‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼šhttps://langchain-ai.github.io/langgraph/how-tos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48ddc3b-210e-4858-8632-4733d6c150fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
