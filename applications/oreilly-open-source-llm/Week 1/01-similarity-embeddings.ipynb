{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b64ece1d-7558-4fb6-a98b-ad06283bb898",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08c809-10c6-42aa-9a01-0477ca426b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5ecf2e-a314-450a-917b-c4b524aff977",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for n in glob.glob(\"un/TXT/Session 77 - 2022/*.txt\"):\n",
    "    data.append({\"country\": os.path.basename(n.replace(\"_77_2022.txt\", \"\")), \"text\": open(n).read() })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0112212d-2b8e-4b38-b2c2-333799200b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c4a6c-52d3-4436-9e45-b1e4f870baec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 500)\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb4820-19d9-4dbf-9690-d62a2df94c59",
   "metadata": {},
   "source": [
    "# Sentence segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e32ba2-bd5e-40cc-bf91-4fe46de6a0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3232940b-b7f3-45d1-9933-e86b5a4eff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5891c67e-f9bd-496c-b4aa-a4d904cbe3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cb5d77-1257-4e77-9ff7-638614016a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202f62ea-b081-4e3d-9719-5d934b566649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs < 1min\n",
    "sentences = []\n",
    "for text in tqdm(df[\"text\"]):\n",
    "    doc = nlp(text)\n",
    "    for sentence in doc.sents:\n",
    "        sentences.append(str(sentence).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d67a487-962e-4e91-ad7b-2aa87309c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d348e426-7359-41c3-a06b-8919d0587d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aefb111-d258-4247-ae4b-6507e8583854",
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"sentences.txt\", \"w\").write(\"@@@\".join(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23bb98c-f62d-4c3a-af7e-8357f9398fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = open(\"sentences.txt\").read().split(\"@@@\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447ac753-3f5d-4eed-a51b-581c37856041",
   "metadata": {},
   "source": [
    "# Encode sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c8379-bb43-43a1-ab84-d1efed83cd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence_transformers -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca1b2b1-9072-4b60-b8c4-4130b8f8d6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975d42f1-1dbd-4181-b2a0-dc5df1362450",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b259f42b-9c45-4fee-b319-afcb37625ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can take a minute or two depending on CPU/GPU configuration\n",
    "sembeddings = model.encode(sentences, show_progress_bar=True, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3734a5b8-8175-4dff-b860-eef739e26cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sembeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3a361c-959b-4fe7-b8c0-241087391e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sembeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fb009d-7d0a-4332-a29d-68aea47e2f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with open(\"sentences-mqa.npy\", \"wb\") as f:\n",
    "    np.save(f, sembeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5a8bd9-1832-4bcb-a3af-21037cb1ad8b",
   "metadata": {},
   "source": [
    "Many more models are available on Hugging Face.\n",
    "\n",
    "Benchmark of models: https://huggingface.co/spaces/mteb/leaderboard\n",
    "\n",
    "Search for all sentence similarity models: https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=trending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9da252-184c-424a-8166-e7646687814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new superfast alternative using ModelVec, new in 3.4, speedup 400x CPU to 25x GPU:\n",
    "# model = SentenceTransformer(\"minishlab/potion-base-8M\", device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9e38bd",
   "metadata": {},
   "source": [
    "## Alternative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb0c72c-c122-40ec-b0b0-9adbb6fb124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# option: truncate_dim=dimensions\n",
    "# option for cpu: backend=\"openvino\"\n",
    "model2 = SentenceTransformer('mixedbread-ai/mxbai-embed-large-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4687ef-fcc7-4c1a-adae-cbbb7035d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can take a minute or two depending on CPU/GPU configuration\n",
    "sembeddings2 = model2.encode(sentences, show_progress_bar=True, \n",
    "                             normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c12bbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sembeddings2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5b75ba-94ed-4de9-9610-d03410448bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want, we could now quantize the embeddings to save space and add performance:\n",
    "from sentence_transformers.quantization import quantize_embeddings\n",
    "binary_embeddings2 = quantize_embeddings(sembeddings2, precision=\"ubinary\")\n",
    "binary_embeddings2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00be3e0-780a-4916-860f-1b965f301e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sentences-mbread.npy\", \"wb\") as f:\n",
    "    np.save(f, sembeddings2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd753ea3",
   "metadata": {},
   "source": [
    "## One more alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25caf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = SentenceTransformer(\"NovaSearch/stella_en_1.5B_v5\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e3cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sembeddings3 = model3.encode(sentences, show_progress_bar=True, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f21b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "sembeddings3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87590881",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sentences-stella.npy\", \"wb\") as f:\n",
    "    np.save(f, sembeddings3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dddad02-fea3-40a0-b9b2-eb4ad04f910b",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416ac725-97c8-4709-aad3-f36cac16a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, text, corpus_embeddings, model, query_prompt_name=None, top=20):\n",
    "    # code query to restrict search space\n",
    "    question_embedding = model.encode(query, normalize_embeddings=True, prompt_name=query_prompt_name)\n",
    "    \n",
    "    # Determine similarity (vectors are normalized)\n",
    "    sim = model.similarity(question_embedding, corpus_embeddings)[0].numpy() \n",
    "    # Alternative: sim = np.dot(corpus_embeddings, question_embedding)\n",
    "    \n",
    "    # Get most similar top_k by sorting\n",
    "    hits = [ { \"text\": text[i], \"score\": sim[i] } \n",
    "                     for i in sim.argsort()[::-1][0:top] ]\n",
    "    \n",
    "    # Return as dataframe\n",
    "    return pd.DataFrame(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a0f3f-6a10-406e-938c-ff7573787206",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed14fc30-5640-4891-8ae1-defa57bf21a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "search(\"The climate crisis is worse for poorer countries.\", sentences, sembeddings, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2a43d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search(\"The climate crisis is worse for poorer countries.\", sentences, sembeddings2, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58ed46d-024f-46ae-89a4-9bc29fea854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search(\"The climate crisis is worse for poorer countries.\", sentences, sembeddings2, model2,\n",
    "       query_prompt_name=\"query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd9ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "search(\"The climate crisis is worse for poorer countries.\", sentences, sembeddings3, model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532d6315-e7fb-4b60-be4f-0c754b24bbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "search(\"The climate crisis is worse for poorer countries.\", sentences, sembeddings3, model3, \n",
    "       query_prompt_name=\"s2p_query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d8412d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
