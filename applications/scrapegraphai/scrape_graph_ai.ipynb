{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Packages Requirements",
   "id": "36a0e92713c032c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%capture --no-stderr\n",
    "%pip install scrapegraphai langchain_scrapegraph dotenv pandas qdrant-client fastembed nest_asyncio\n",
    "#playwright install\n",
    "%pip install\n",
    "%pip install -U duckduckgo-search\n",
    "%pip install scrapegraphai'[other-language-models]'\n",
    "%pip install scrapegraphai'[more-semantic-options]'\n",
    "%pip install scrapegraphai'[more-browser-options]'"
   ],
   "id": "20f06f946ecec666",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. SmartScraperGraph with OpenAI",
   "id": "2110dbff6c89813e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import json\n",
    "from scrapegraphai.graphs import SmartScraperGraph, DepthSearchGraph\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define the configuration for the scraping pipeline\n",
    "graph_config = {\n",
    "    \"llm\": {\n",
    "        \"api_key\": api_key,\n",
    "        \"model\": \"openai/gpt-4o-mini\",\n",
    "    },\n",
    "    \"verbose\": True,\n",
    "    \"headless\": True,\n",
    "    \"depth\": 2,\n",
    "    \"only_inside_links\": False\n",
    "}\n",
    "\n",
    "# Create the SmartScraperGraph instance\n",
    "smart_scraper_graph = SmartScraperGraph(\n",
    "    prompt=\"Extract all the posts from the website\",\n",
    "    source=\"https://www.aivi.fyi/\",\n",
    "    config=graph_config\n",
    ")\n",
    "# Run the pipeline\n",
    "result = smart_scraper_graph.run()\n",
    "print(json.dumps(result, indent=4,ensure_ascii=False))\n",
    "\n",
    "\n",
    "# search_graph = DepthSearchGraph(\n",
    "#     prompt=\"List me all the projects with their description\",\n",
    "#     source=\"https://perinim.github.io\",\n",
    "#     config=graph_config\n",
    "# )\n",
    "# result = search_graph.run()\n",
    "# print(result)"
   ],
   "id": "8936d1c1940a3b2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "一名打算獨自出國旅行的上班族，考慮到安排行程都需要花很多時間搜集資料，打算參考日本在地的旅遊網站內容(https://osaka.letsgojp.com/archives/548388/)，來安排京都熱門的旅遊景點。使用python開發，並透過BeautifulSoup套件來擷取，該網頁內容景點相關的內容。 每次都會隨機提供三個熱門景點與相關參考資訊，\"如果不在推薦景點內，系統會另外提供其他熱門景點。只有顯示網頁回應200時才會開始推薦。每次執行都重新讀取網頁資訊，不需要存檔。\n",
    "\n",
    "1.一名計劃獨自出國旅行的上班族，考慮到安排行程需要花費大量時間搜集資料，決定參考日本在地的旅遊網站內容。\n",
    "2.使用Python開發，並透過BeautifulSoup套件來擷取該網頁中與景點相關的內容。\n",
    "3.每次都會隨機提供三個熱門景點與相關參考資訊。如果不在推薦景點內，系統會另外提供其他熱門景點。\n",
    "4.只有在網頁回應狀態碼為200時才會開始推薦。\n",
    "5.每次執行時都會重新讀取網頁資訊，不需要存檔。"
   ],
   "id": "68e56385f72c1684"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "\n",
    "# 參考網址\n",
    "url = 'https://osaka.letsgojp.com/archives/548388/'\n",
    "\n",
    "# 發送 GET 請求\n",
    "response = requests.get(url)\n",
    "response.encoding = 'utf-8'\n",
    "\n",
    "# 確認請求成功\n",
    "if response.status_code == 200:\n",
    "    # 解析 HTML\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # 擷取文章主體\n",
    "    article = soup.find('div', class_='entry-content clearfix')\n",
    "\n",
    "    # 初始化資料列表\n",
    "    playinfo=[]\n",
    "    data=[]\n",
    "    planinfo=[]\n",
    "    # 提取標題\n",
    "    title = soup.find('h1', class_='h3 my-3').text.strip()\n",
    "\n",
    "\n",
    "    # 提取景點資訊\n",
    "    location_data = article.find_all('p', {'align': 'justify'})\n",
    "\n",
    "    for locations in location_data:\n",
    "        # 取得景點名稱\n",
    "        span_tag = locations.find('span')\n",
    "        names = span_tag.text.strip() if span_tag else None\n",
    "\n",
    "        # 取得景點資訊\n",
    "        info = locations.get_text(strip=True)\n",
    "        if names:\n",
    "            info = info.replace(names, \"\")  # 移除名稱\n",
    "        info = info.replace('\"', '').replace(\"\\r\\n\", \"\").replace(\"\\r\", \"\").replace(\"\\n\", \"\").replace(\"・\", \" ❊ \")\n",
    "\n",
    "        # 取得官方網站連結\n",
    "        a_tag = locations.find('a')\n",
    "        web_url = a_tag['href'] if a_tag else None\n",
    "        if web_url:\n",
    "            info = info.replace(\"官方網站\", f\"官方網站：{web_url}\")\n",
    "\n",
    "        # 存入 `playinfo`\n",
    "        if names:\n",
    "            playinfo.append([names, info])\n",
    "\n",
    "        #隨機推薦三個景點\n",
    "        if len(playinfo) >= 3:\n",
    "            visit_places = random.sample(playinfo, 3)\n",
    "        else:\n",
    "            visit_places = playinfo  # 如果不足 3 個，就顯示所有\n",
    "\n",
    "    # 顯示隨機推薦的 3 個景點\n",
    "    print(f\"根據'{title}'網站介紹，隨機推薦的 3 個景點：\\n\")\n",
    "    for place in visit_places:\n",
    "        data.append(place[0])\n",
    "        planinfo=f\"景點：{place[0]}\\n參考資訊:{place[1]}\\n\"\n",
    "        planinfo=planinfo.replace(\" ❊ \", \" \\n ❊ \")\n",
    "        print(f'{planinfo}')\n",
    "\n",
    "\n",
    "    # 提取 playinfo 裡的景點名稱\n",
    "    planinfo = {item[0] for item in playinfo}\n",
    "\n",
    "    # 找出不在推薦景點中的名稱\n",
    "    extra_places = [name for name in planinfo if name not in data]\n",
    "    print(\"\\n下次旅行可參考的地點:\\n\", \"、\".join(extra_places))\n",
    "\n",
    "else:\n",
    "    print(f'無法取得網頁內容，狀態碼：{response.status_code}')"
   ],
   "id": "cf92c717c35861d1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
