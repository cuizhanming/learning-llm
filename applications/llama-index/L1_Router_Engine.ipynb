{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd7c4c87",
   "metadata": {},
   "source": [
    "# Lesson 1: Router Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877df988",
   "metadata": {},
   "source": [
    "Welcome to Lesson 1.\n",
    "\n",
    "To access the `requirements.txt` file, the data/pdf file required for this lesson and the `helper` and `utils` modules, please go to the `File` menu and select`Open...`.\n",
    "\n",
    "I hope you enjoy this course!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357c97c9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "ab5f4f4a-5890-451c-8869-24606ef9f396",
   "metadata": {
    "height": 64,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-09T15:13:16.286968Z",
     "start_time": "2025-02-09T15:13:16.277452Z"
    }
   },
   "source": [
    "from helper import get_openai_api_key\n",
    "\n",
    "OPENAI_API_KEY = get_openai_api_key()"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "ffc9b4f4-64d4-4266-9889-54db90e00ee9",
   "metadata": {
    "height": 64,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-09T15:13:14.999834Z",
     "start_time": "2025-02-09T15:13:14.995292Z"
    }
   },
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "49fca250",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ae2a8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "To download this paper, below is the needed code:\n",
    "\n",
    "#!wget \"https://openreview.net/pdf?id=VtmBAGCN7o\" -O metagpt.pdf\n",
    "\n",
    "**Note**: The pdf file is included with this lesson. To access it, go to the `File` menu and select`Open...`."
   ]
  },
  {
   "cell_type": "code",
   "id": "5c7f012d-dcd3-4881-a568-72dd27d79159",
   "metadata": {
    "height": 81,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-09T15:12:42.814224Z",
     "start_time": "2025-02-09T15:12:40.955551Z"
    }
   },
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(input_files=[\"pdf/metagpt.pdf\"]).load_data()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "6b48a301",
   "metadata": {},
   "source": [
    "## Define LLM and Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "id": "8a537bc0-78ee-4dda-a43f-60fd80062df6",
   "metadata": {
    "height": 81,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-09T15:12:45.798747Z",
     "start_time": "2025-02-09T15:12:45.708165Z"
    }
   },
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "de0660ee-b231-4351-b158-d8ad023e00b5",
   "metadata": {
    "height": 115,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-09T15:12:48.646971Z",
     "start_time": "2025-02-09T15:12:47.869414Z"
    }
   },
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "997c7559",
   "metadata": {},
   "source": [
    "## Define Summary Index and Vector Index over the Same Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "73d01b01-bc74-432a-8d92-07b9e86498b0",
   "metadata": {
    "height": 81,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-09T15:12:52.578889Z",
     "start_time": "2025-02-09T15:12:49.917552Z"
    }
   },
   "source": [
    "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "vector_index = VectorStoreIndex(nodes)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "f9898d3f",
   "metadata": {},
   "source": [
    "## Define Query Engines and Set Metadata"
   ]
  },
  {
   "cell_type": "code",
   "id": "44cd7046-c714-4920-b077-b3ded917862f",
   "metadata": {
    "height": 98,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-09T15:12:58.429810Z",
     "start_time": "2025-02-09T15:12:58.427318Z"
    }
   },
   "source": [
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "vector_query_engine = vector_index.as_query_engine()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "6a1d6d75-247e-426a-8ef4-b49225c24796",
   "metadata": {
    "height": 285,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-09T15:13:00.270728Z",
     "start_time": "2025-02-09T15:13:00.266966Z"
    }
   },
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful for summarization questions related to MetaGPT\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=(\n",
    "        \"Useful for retrieving specific context from the MetaGPT paper.\"\n",
    "    ),\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "98d2c152",
   "metadata": {},
   "source": [
    "## Define Router Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "id": "00734d7c-638a-4d63-ab1f-7f5a92a65119",
   "metadata": {
    "height": 217,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-09T15:13:02.633401Z",
     "start_time": "2025-02-09T15:13:02.630255Z"
    }
   },
   "source": [
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "\n",
    "\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        summary_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "fe3f0a76-68a8-444d-867f-d084bb3ff112",
   "metadata": {
    "height": 47,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-09T15:13:24.802705Z",
     "start_time": "2025-02-09T15:13:20.105918Z"
    }
   },
   "source": [
    "response = query_engine.query(\"What is the summary of the document?\")\n",
    "print(str(response))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;3;38;5;200mSelecting query engine 0: Useful for summarization questions related to MetaGPT.\n",
      "\u001B[0mThe document introduces MetaGPT, a meta-programming framework that enhances multi-agent systems based on Large Language Models (LLMs) through role specialization, workflow management, and efficient communication mechanisms. It discusses the development of a software application called the \"Drawing App\" using MetaGPT, outlining the process from defining requirements to testing the application. The document also covers the performance of MetaGPT, the impact of instruction levels on task outcomes, challenges addressed by MetaGPT's designs, and ethical concerns related to its implementation.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "d3fedea0-f2a9-46bb-8aaf-287df65b8fff",
   "metadata": {
    "height": 30,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-09T15:13:27.356760Z",
     "start_time": "2025-02-09T15:13:27.353912Z"
    }
   },
   "source": [
    "print(len(response.source_nodes))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "af8c31b3-8e22-4ad9-9825-b8de21bd03c0",
   "metadata": {
    "height": 81,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-09T15:13:31.387572Z",
     "start_time": "2025-02-09T15:13:29.261581Z"
    }
   },
   "source": [
    "response = query_engine.query(\n",
    "    \"How do agents share information with other agents?\"\n",
    ")\n",
    "print(str(response))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;3;38;5;200mSelecting query engine 1: This choice is more relevant as it specifically mentions retrieving specific context, which would be necessary for understanding how agents share information with other agents..\n",
      "\u001B[0mAgents share information with other agents by utilizing a shared message pool where they can publish structured messages. Additionally, agents can subscribe to relevant messages based on their profiles. This approach allows for transparent exchange of information among agents, enabling them to access and retrieve necessary information directly from the shared pool without the need for individual inquiries or waiting for responses.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "aed060ee",
   "metadata": {},
   "source": [
    "## Let's put everything together"
   ]
  },
  {
   "cell_type": "code",
   "id": "d8f92e0b-1c54-489b-b8dd-41ebaafb380a",
   "metadata": {
    "height": 64,
    "ExecuteTime": {
     "end_time": "2025-02-09T15:13:42.076506Z",
     "start_time": "2025-02-09T15:13:40.268343Z"
    }
   },
   "source": [
    "from utils import get_router_query_engine\n",
    "\n",
    "query_engine = get_router_query_engine(\"pdf/metagpt.pdf\")"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "ec1a43f3-77dc-472a-8adc-56551c00a0ff",
   "metadata": {
    "height": 47,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-09T15:13:46.636509Z",
     "start_time": "2025-02-09T15:13:44.124707Z"
    }
   },
   "source": [
    "response = query_engine.query(\"Tell me about the ablation study results?\")\n",
    "print(str(response))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;3;38;5;200mSelecting query engine 1: Ablation study results are specific context from the MetaGPT paper, making choice 2 the most relevant..\n",
      "\u001B[0mThe ablation study results demonstrate the effectiveness of MetaGPT in addressing challenges related to context utilization, reducing hallucinations in software generation, and managing information overload. The study highlights how MetaGPT's unique designs successfully unfold short natural language descriptions accurately, maintain information validity in lengthy contexts, and reduce code hallucination problems commonly faced by large language models. Additionally, MetaGPT's use of a global message pool and subscription mechanism effectively tackles information overload by streamlining communication and filtering out irrelevant contexts, ultimately enhancing the relevance and utility of the information provided.\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
